{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "644cf55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-05-22 07:08:28--  https://huggingface.co/Helsinki-NLP/opus-mt-mul-en/resolve/main/source.spm\n",
      "Resolving huggingface.co (huggingface.co)... 34.232.89.2, 18.214.24.217, 34.197.58.156, ...\n",
      "Connecting to huggingface.co (huggingface.co)|34.232.89.2|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 706917 (690K) [application/octet-stream]\n",
      "Saving to: ‘source.spm’\n",
      "\n",
      "source.spm          100%[===================>] 690.35K   528KB/s    in 1.3s    \n",
      "\n",
      "2022-05-22 07:08:31 (528 KB/s) - ‘source.spm’ saved [706917/706917]\n",
      "\n",
      "--2022-05-22 07:08:32--  https://huggingface.co/Helsinki-NLP/opus-mt-mul-en/resolve/main/target.spm\n",
      "Resolving huggingface.co (huggingface.co)... 18.214.24.217, 34.197.58.156, 23.21.14.202, ...\n",
      "Connecting to huggingface.co (huggingface.co)|18.214.24.217|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 791194 (773K) [application/octet-stream]\n",
      "Saving to: ‘target.spm’\n",
      "\n",
      "target.spm          100%[===================>] 772.65K   553KB/s    in 1.4s    \n",
      "\n",
      "2022-05-22 07:08:34 (553 KB/s) - ‘target.spm’ saved [791194/791194]\n",
      "\n",
      "--2022-05-22 07:08:35--  https://huggingface.co/Helsinki-NLP/opus-mt-mul-en/raw/main/tokenizer_config.json\n",
      "Resolving huggingface.co (huggingface.co)... 34.197.58.156, 23.21.14.202, 34.232.89.2, ...\n",
      "Connecting to huggingface.co (huggingface.co)|34.197.58.156|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 44 [application/json]\n",
      "Saving to: ‘tokenizer_config.json’\n",
      "\n",
      "tokenizer_config.js 100%[===================>]      44  --.-KB/s    in 0s      \n",
      "\n",
      "2022-05-22 07:08:36 (5.21 MB/s) - ‘tokenizer_config.json’ saved [44/44]\n",
      "\n",
      "--2022-05-22 07:08:37--  https://huggingface.co/Helsinki-NLP/opus-mt-mul-en/raw/main/vocab.json\n",
      "Resolving huggingface.co (huggingface.co)... 23.21.14.202, 34.232.89.2, 18.214.24.217, ...\n",
      "Connecting to huggingface.co (huggingface.co)|23.21.14.202|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1423947 (1.4M) [application/json]\n",
      "Saving to: ‘vocab.json’\n",
      "\n",
      "vocab.json          100%[===================>]   1.36M   643KB/s    in 2.2s    \n",
      "\n",
      "2022-05-22 07:08:40 (643 KB/s) - ‘vocab.json’ saved [1423947/1423947]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !wget https://huggingface.co/Helsinki-NLP/opus-mt-mul-en/resolve/main/source.spm\n",
    "# !wget https://huggingface.co/Helsinki-NLP/opus-mt-mul-en/resolve/main/target.spm\n",
    "# !wget https://huggingface.co/Helsinki-NLP/opus-mt-mul-en/raw/main/tokenizer_config.json\n",
    "# !wget https://huggingface.co/Helsinki-NLP/opus-mt-mul-en/raw/main/vocab.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b41df616",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -R outputs/checkpoint-1905-epoch-5 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f863ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ep2/source.spm checkpoint-1905-epoch-5/\n",
    "!cp ep2/target.spm checkpoint-1905-epoch-5/\n",
    "!cp ep2/tokenizer_config.json checkpoint-1905-epoch-5/\n",
    "!cp ep2/vocab.json checkpoint-1905-epoch-5/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb2c1b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp  -R outputs/checkpoint-1905-epoch-5/* ep3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b984dedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-22 17:49:43.749526: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.seq2seq import Seq2SeqModel,Seq2SeqArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e134c5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "415c7e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = Seq2SeqArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ad7d2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqArgs(adafactor_beta1=None, adafactor_clip_threshold=1.0, adafactor_decay_rate=-0.8, adafactor_eps=(1e-30, 0.001), adafactor_relative_step=True, adafactor_scale_parameter=True, adafactor_warmup_init=True, adam_epsilon=1e-08, best_model_dir='outputs/best_model', cache_dir='cache_dir/', config={}, cosine_schedule_num_cycles=0.5, custom_layer_parameters=[], custom_parameter_groups=[], dataloader_num_workers=0, do_lower_case=False, dynamic_quantize=False, early_stopping_consider_epochs=False, early_stopping_delta=0, early_stopping_metric='eval_loss', early_stopping_metric_minimize=True, early_stopping_patience=3, encoding=None, eval_batch_size=8, evaluate_during_training=False, evaluate_during_training_silent=True, evaluate_during_training_steps=2000, evaluate_during_training_verbose=False, evaluate_each_epoch=True, fp16=True, gradient_accumulation_steps=1, learning_rate=4e-05, local_rank=-1, logging_steps=50, loss_type=None, loss_args={}, manual_seed=None, max_grad_norm=1.0, max_seq_length=128, model_name=None, model_type=None, multiprocessing_chunksize=-1, n_gpu=1, no_cache=False, no_save=False, not_saved_args=[], num_train_epochs=1, optimizer='AdamW', output_dir='outputs/', overwrite_output_dir=False, polynomial_decay_schedule_lr_end=1e-07, polynomial_decay_schedule_power=1.0, process_count=78, quantized_model=False, reprocess_input_data=True, save_best_model=True, save_eval_checkpoints=True, save_model_every_epoch=True, save_optimizer_and_scheduler=True, save_steps=2000, scheduler='linear_schedule_with_warmup', silent=False, skip_special_tokens=True, tensorboard_dir=None, thread_count=None, tokenizer_name=None, tokenizer_type=None, train_batch_size=8, train_custom_parameters_only=False, use_cached_eval_features=False, use_early_stopping=False, use_hf_datasets=False, use_multiprocessing=True, use_multiprocessing_for_evaluation=True, wandb_kwargs={}, wandb_project=None, warmup_ratio=0.06, warmup_steps=0, weight_decay=0.0, model_class='Seq2SeqModel', base_marian_model_name=None, dataset_class=None, dataset_cache_dir=None, do_sample=False, early_stopping=True, evaluate_generated_text=False, faiss_d=768, faiss_m=128, include_title_in_knowledge_dataset=True, length_penalty=2.0, max_length=20, max_steps=-1, num_beams=1, num_return_sequences=1, rag_embed_batch_size=16, repetition_penalty=1.0, save_knowledge_dataset=True, save_knowledge_dataset_with_checkpoints=False, split_text_character=' ', split_text_n=100, src_lang='en_XX', tgt_lang='ro_RO', top_k=None, top_p=None, use_multiprocessed_decoding=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "080cb405",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2SeqModel(\n",
    "    encoder_decoder_type=\"marian\",\n",
    "    encoder_decoder_name=\"checkpoint-1905-epoch-5/\",\n",
    "    args=model_args,\n",
    "    use_cuda=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72209f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3cb293ec725476fa73d95557753ba66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating outputs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3524: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and the tokenizer under the `as_target_tokenizer` context manager to prepare\n",
      "your targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "with tokenizer.as_target_tokenizer():\n",
      "    labels = tokenizer(tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(['เล่า'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c8de717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d326b384",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = os.path.join('..','dataset','cs')\n",
    "\n",
    "train_filepaths = os.path.join(path_dataset,'train.tsv')\n",
    "dev_filepaths = os.path.join(path_dataset,'dev.tsv')\n",
    "test_filepaths = os.path.join(path_dataset,'test.tsv')\n",
    "\n",
    "train_df = pd.read_csv(train_filepaths,sep=\"\\t\")\n",
    "dev_df = pd.read_csv(dev_filepaths,sep=\"\\t\")\n",
    "test_df = pd.read_csv(test_filepaths,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff9e2778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    new_df=pd.DataFrame()\n",
    "    new_df[\"input_text\"]=[str(i) for i in data_path['word']]\n",
    "    new_df[\"target_text\"] =[str(i) for i in data_path['roman']]\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9929f5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = load_data(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5728bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ก๊อปปี้'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test_df['input_text'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3604fc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7920563503704a2799c486251556cc46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating outputs:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model.predict(list(test_df['input_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ad445e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boekai'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e8c131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = list(test_df['target_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f10182a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hedenbergite'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97b63aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pi'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b406851",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jiwer import cer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76d5dbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(s):\n",
    "    if s.startswith('▁'):\n",
    "        s=s.replace('▁','',1)\n",
    "    return s.replace('▁',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc3a74c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7565232722143864"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cer(ground_truth,[clean(i) for i in pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11afa35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pi',\n",
       " 'sai',\n",
       " '',\n",
       " 'nai',\n",
       " 'thonai',\n",
       " 'lon',\n",
       " 'we',\n",
       " 'set',\n",
       " 'khokhen',\n",
       " 'sula',\n",
       " 'lileokalile',\n",
       " '',\n",
       " 'koen',\n",
       " '',\n",
       " 'mik',\n",
       " 'chik',\n",
       " 'mandai',\n",
       " 'khonai',\n",
       " '',\n",
       " 'dofai',\n",
       " '',\n",
       " 'nopthailolai',\n",
       " 'momai',\n",
       " 'lian',\n",
       " 'lai',\n",
       " 'lekchan',\n",
       " 'i',\n",
       " 'inoensatathai',\n",
       " 'thin',\n",
       " 'rai',\n",
       " 'we',\n",
       " 'boe',\n",
       " 'soe',\n",
       " 'dominiam',\n",
       " 'thokhoerensi',\n",
       " '',\n",
       " 'nenlai',\n",
       " 'rin',\n",
       " '',\n",
       " 'thonai',\n",
       " 'toe',\n",
       " 'so',\n",
       " 'chi',\n",
       " 'mai',\n",
       " 'linsai',\n",
       " 'ki',\n",
       " 'soe',\n",
       " '',\n",
       " 'pithan',\n",
       " '',\n",
       " 'wi',\n",
       " 'soen',\n",
       " 'nadai',\n",
       " 'tho',\n",
       " 'in',\n",
       " 'fonia',\n",
       " 'sai',\n",
       " '',\n",
       " 'krit',\n",
       " 'daioksai',\n",
       " '',\n",
       " '',\n",
       " 'men',\n",
       " 'lip',\n",
       " 'boe',\n",
       " 'ring',\n",
       " 'then',\n",
       " 'mosom',\n",
       " '',\n",
       " 'ta',\n",
       " 'fi',\n",
       " 'phrai',\n",
       " 'thoai',\n",
       " 'lik',\n",
       " '',\n",
       " 'tam',\n",
       " '',\n",
       " 'fio',\n",
       " 'khokhaeparikhonat',\n",
       " 'khokhesoi',\n",
       " 'let',\n",
       " 'phet',\n",
       " 'wan',\n",
       " 'thaeklen',\n",
       " '',\n",
       " 'khrinai',\n",
       " 'thorai',\n",
       " '',\n",
       " 'ik',\n",
       " 'khonikhoen',\n",
       " 'rit',\n",
       " 'khot',\n",
       " 'salai',\n",
       " 'dam',\n",
       " 'toe',\n",
       " 'men',\n",
       " 'nekchan',\n",
       " 'kae',\n",
       " 'boe',\n",
       " 'khonla',\n",
       " 'nik',\n",
       " 'toe',\n",
       " 'nosoisai',\n",
       " 'laep',\n",
       " 'lap',\n",
       " 'wisai',\n",
       " 'si',\n",
       " 'chaep',\n",
       " '',\n",
       " 'men',\n",
       " 'phiotoe',\n",
       " 'laeng',\n",
       " '',\n",
       " 'choe',\n",
       " 'choe',\n",
       " 'ting',\n",
       " '',\n",
       " 'khokhowai',\n",
       " 'woerai',\n",
       " '',\n",
       " 'soe',\n",
       " 'inohiomai',\n",
       " '',\n",
       " 'ket',\n",
       " '',\n",
       " '',\n",
       " 'sai',\n",
       " '',\n",
       " 'rechan',\n",
       " '',\n",
       " 'lai',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'chin',\n",
       " 'lit',\n",
       " '',\n",
       " '',\n",
       " 'ki',\n",
       " 'ri',\n",
       " '',\n",
       " 'ri',\n",
       " 'si',\n",
       " 'phi',\n",
       " '',\n",
       " '',\n",
       " 'not',\n",
       " 'si',\n",
       " '',\n",
       " '',\n",
       " 'ti',\n",
       " 'litdoe',\n",
       " '',\n",
       " 'khai',\n",
       " '',\n",
       " '',\n",
       " 'ai',\n",
       " '',\n",
       " 'tani',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'tada',\n",
       " 'lai',\n",
       " 'li',\n",
       " '',\n",
       " 'pho',\n",
       " 'rit',\n",
       " 'tikram',\n",
       " 'rai',\n",
       " 'sonai',\n",
       " 'fairin',\n",
       " '',\n",
       " 'soe',\n",
       " '',\n",
       " '',\n",
       " 'ngkoenmam',\n",
       " '',\n",
       " 'maket',\n",
       " 'choeri',\n",
       " 'sarai',\n",
       " 'rian',\n",
       " 'bonai',\n",
       " 'poe',\n",
       " '',\n",
       " 'lai',\n",
       " 'yu',\n",
       " 'sin',\n",
       " 'halai',\n",
       " '',\n",
       " 'khom',\n",
       " 'set',\n",
       " 'limanai',\n",
       " 'foe',\n",
       " 'doe',\n",
       " 'lai',\n",
       " '',\n",
       " 'thit',\n",
       " 'monthai',\n",
       " 'koen',\n",
       " 'ka',\n",
       " '',\n",
       " 'namon',\n",
       " 'wai',\n",
       " 'mik',\n",
       " 'fi',\n",
       " 'rai',\n",
       " 'kai',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'khoen',\n",
       " '',\n",
       " '',\n",
       " 'khakhadao',\n",
       " 'khedian',\n",
       " 'lai',\n",
       " '',\n",
       " 'rai',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'lindrai',\n",
       " '',\n",
       " 'nai',\n",
       " '',\n",
       " 'raepsakai',\n",
       " 'lit',\n",
       " '',\n",
       " 'woeri',\n",
       " 'ning',\n",
       " 'mo',\n",
       " 'chachet',\n",
       " 'burai',\n",
       " 'di',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'niam',\n",
       " 'elimen',\n",
       " 'saekkharai',\n",
       " 'loenning',\n",
       " 'daesai',\n",
       " 'i',\n",
       " 'li',\n",
       " 'do',\n",
       " 'fik',\n",
       " 'toe',\n",
       " 'kham',\n",
       " '',\n",
       " 'sanai',\n",
       " 'nik',\n",
       " 'woe',\n",
       " '',\n",
       " 'khonsaen',\n",
       " 'kai',\n",
       " 'loe',\n",
       " '',\n",
       " 'nichiam',\n",
       " 'nik',\n",
       " 'rit',\n",
       " 'ksai',\n",
       " 'sido',\n",
       " 'sanai',\n",
       " 'sarathop',\n",
       " 'liam',\n",
       " 'thanomaeknithai',\n",
       " '',\n",
       " '',\n",
       " 'hao',\n",
       " 'khoi',\n",
       " 'thalai',\n",
       " 'fi',\n",
       " '',\n",
       " 'it',\n",
       " 'buk',\n",
       " 'kholai',\n",
       " 'yakai',\n",
       " '',\n",
       " 'obiam',\n",
       " '',\n",
       " 'bon',\n",
       " 'kholai',\n",
       " '',\n",
       " 'khlap',\n",
       " 'khetbai',\n",
       " '',\n",
       " 'samut',\n",
       " 'phai',\n",
       " 'rat',\n",
       " 'wudai',\n",
       " '',\n",
       " '',\n",
       " 'kit',\n",
       " 'bas',\n",
       " 'to',\n",
       " 'koen',\n",
       " 'daetsoen',\n",
       " 'rian',\n",
       " 'ti',\n",
       " 'kit',\n",
       " '',\n",
       " '',\n",
       " 'chenbaekhai',\n",
       " 'thom',\n",
       " '',\n",
       " '',\n",
       " 'kat',\n",
       " '',\n",
       " '',\n",
       " 'wae',\n",
       " 'maep',\n",
       " 'bon',\n",
       " '',\n",
       " 'mot',\n",
       " 'bi',\n",
       " 'rum',\n",
       " '',\n",
       " 'sin',\n",
       " 'khot',\n",
       " 'to',\n",
       " '',\n",
       " 'kholi',\n",
       " '',\n",
       " 'ta',\n",
       " '',\n",
       " 'kai',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'phethisuem',\n",
       " 'thoen',\n",
       " '',\n",
       " 'chenthai',\n",
       " 'ao',\n",
       " 'saton',\n",
       " 'boi',\n",
       " 'kitai',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'woe',\n",
       " 'soe',\n",
       " 'koen',\n",
       " 'cho',\n",
       " '',\n",
       " 'daenna',\n",
       " 'thin',\n",
       " '',\n",
       " 'ti',\n",
       " '',\n",
       " 'thoen',\n",
       " 'nok',\n",
       " '',\n",
       " 'rum',\n",
       " '',\n",
       " 'liat',\n",
       " 'lat',\n",
       " '',\n",
       " 'ktharop',\n",
       " '',\n",
       " 'dok',\n",
       " 'phola',\n",
       " 'khon',\n",
       " 'thisuem',\n",
       " 'kat',\n",
       " 'rionik',\n",
       " 'khio',\n",
       " 'mintan',\n",
       " '',\n",
       " 'boeri',\n",
       " 'baettik',\n",
       " 'p',\n",
       " 'net',\n",
       " 'sa',\n",
       " 'kan',\n",
       " 'kholi',\n",
       " 'ek',\n",
       " 'toe',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'chit',\n",
       " '',\n",
       " 'saendai',\n",
       " '',\n",
       " 'mian',\n",
       " '',\n",
       " 'muthinai',\n",
       " 'khio',\n",
       " 'ret',\n",
       " '',\n",
       " 'dotsoe',\n",
       " '',\n",
       " 'ko',\n",
       " 'si',\n",
       " '',\n",
       " '',\n",
       " 'chicham',\n",
       " 'soe',\n",
       " '',\n",
       " '',\n",
       " 'then',\n",
       " '',\n",
       " 'falo',\n",
       " 'ao',\n",
       " '',\n",
       " '',\n",
       " 'doe',\n",
       " 'littik',\n",
       " 'odata',\n",
       " 'selloe',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'dik',\n",
       " '',\n",
       " 'koe',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'senthai',\n",
       " 'woi',\n",
       " 'fi',\n",
       " '',\n",
       " '',\n",
       " 'sifikphai',\n",
       " 'si',\n",
       " 'toe',\n",
       " 'mot',\n",
       " 'wet',\n",
       " 'kraem',\n",
       " '',\n",
       " 'kraemmoe',\n",
       " 'nai',\n",
       " 'thabun',\n",
       " 'ek',\n",
       " 'fom',\n",
       " 'thothai',\n",
       " '',\n",
       " 'bun',\n",
       " 'chektoe',\n",
       " 'nolai',\n",
       " 'oksin',\n",
       " 'tothai',\n",
       " 'sonik',\n",
       " 'toe',\n",
       " 'lai',\n",
       " 'sai',\n",
       " 'thai',\n",
       " '',\n",
       " 'wet',\n",
       " 'mit',\n",
       " 'lam',\n",
       " 'khaket',\n",
       " 'thai',\n",
       " '',\n",
       " 'ket',\n",
       " 'ot',\n",
       " 'mithiam',\n",
       " '',\n",
       " 'thinam',\n",
       " 'chiokhlet',\n",
       " 'mochan',\n",
       " 'luang',\n",
       " 'thon',\n",
       " 'bun',\n",
       " 'choe',\n",
       " 'nomitoe',\n",
       " 'besai',\n",
       " 'thalai',\n",
       " 'fom',\n",
       " '',\n",
       " 'fut',\n",
       " 'suthikhan',\n",
       " 'buk',\n",
       " 'choe',\n",
       " 'chan',\n",
       " '',\n",
       " 'naen',\n",
       " '',\n",
       " 'khek',\n",
       " 'fotforai',\n",
       " '',\n",
       " '',\n",
       " 'li',\n",
       " 'lip',\n",
       " 'buk',\n",
       " 'lut',\n",
       " 'chai',\n",
       " 'rin',\n",
       " 'boekai',\n",
       " 'toe',\n",
       " 'kusanai',\n",
       " 'thot',\n",
       " '',\n",
       " 'chan',\n",
       " 'sellaenotboekai',\n",
       " '',\n",
       " 'dinai',\n",
       " '',\n",
       " '',\n",
       " 'nai',\n",
       " '',\n",
       " 'loerai',\n",
       " '',\n",
       " 'thinaelkoho',\n",
       " 'thaengkholiai',\n",
       " 'kun',\n",
       " 'sik',\n",
       " 'khrokhomphiotoe',\n",
       " '',\n",
       " 'dawai',\n",
       " '',\n",
       " 'ret',\n",
       " 'then',\n",
       " '',\n",
       " 'ek',\n",
       " 'ksisi',\n",
       " 'lakhon',\n",
       " 'mi',\n",
       " 'toe',\n",
       " 'nisai',\n",
       " '',\n",
       " 'thot',\n",
       " 'khron',\n",
       " 'lai',\n",
       " 'thin',\n",
       " 'khai',\n",
       " 'choerai',\n",
       " 'hakanoso',\n",
       " 'lisai',\n",
       " 'finresinkhek',\n",
       " 'khrosop',\n",
       " 'su',\n",
       " 'lai',\n",
       " 'woe',\n",
       " '',\n",
       " 'nofen',\n",
       " 'li',\n",
       " 'si',\n",
       " 'khripathai',\n",
       " '',\n",
       " '',\n",
       " 'toe',\n",
       " 'ka',\n",
       " 'thiniam',\n",
       " 'wio',\n",
       " 'mot',\n",
       " '',\n",
       " 'samwae',\n",
       " 'boeri',\n",
       " 'khonthon',\n",
       " 'kaniam',\n",
       " 'bi',\n",
       " 'san',\n",
       " 'in',\n",
       " 'bot',\n",
       " 'da',\n",
       " 'diam',\n",
       " 'sing',\n",
       " 'nowo',\n",
       " 'chatheliarai',\n",
       " 'da',\n",
       " 'thichiam',\n",
       " 'chan',\n",
       " 'ophluarodon',\n",
       " 'phat',\n",
       " 'nsenai',\n",
       " 'rithuem',\n",
       " '',\n",
       " 'ba',\n",
       " 'thop',\n",
       " 'wiai',\n",
       " 'ma',\n",
       " 'choe',\n",
       " 'bradorai',\n",
       " '',\n",
       " 'lamai',\n",
       " 'filai',\n",
       " 'sadai',\n",
       " 'naethai',\n",
       " '',\n",
       " 'noekrup entoephrai',\n",
       " 'minbi 1',\n",
       " 'lum',\n",
       " 'siraeptoe',\n",
       " 'thailiti',\n",
       " 'khon',\n",
       " 'toe',\n",
       " 'phoechai',\n",
       " 'doekphi',\n",
       " 'diam',\n",
       " 'lai',\n",
       " 'ta',\n",
       " '',\n",
       " '',\n",
       " 'nai',\n",
       " 'choe',\n",
       " 'khai',\n",
       " 'phet',\n",
       " 'si',\n",
       " 'chop',\n",
       " 'thai',\n",
       " 'bon',\n",
       " 'noe',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'na',\n",
       " 'foetfoethai',\n",
       " 'si',\n",
       " 'let',\n",
       " '',\n",
       " '',\n",
       " 'ming',\n",
       " 'lai',\n",
       " 'boeri',\n",
       " 'pot',\n",
       " 'rolai',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'inosorat',\n",
       " 'sutfut',\n",
       " 'chianai',\n",
       " 'khrip',\n",
       " '',\n",
       " 'tha',\n",
       " 'ok',\n",
       " 'kolai',\n",
       " 'toe',\n",
       " 'lit',\n",
       " 'kai',\n",
       " '',\n",
       " '',\n",
       " 'rai',\n",
       " '',\n",
       " 'krim',\n",
       " 'ket',\n",
       " 'ta insataen prodio',\n",
       " 'siam',\n",
       " 'sit',\n",
       " 'moe',\n",
       " '',\n",
       " 'fon',\n",
       " '',\n",
       " 'sai',\n",
       " '',\n",
       " 'chin',\n",
       " 'net',\n",
       " 'phisam',\n",
       " '',\n",
       " 'toe',\n",
       " 'thronik',\n",
       " 'khao',\n",
       " 'monsai',\n",
       " 'sibi',\n",
       " 'nik',\n",
       " 'odin',\n",
       " 'phai',\n",
       " 'siden',\n",
       " 'khaeoriam',\n",
       " 'thiniam',\n",
       " 'sai',\n",
       " 'phaet',\n",
       " 'boeborai',\n",
       " '',\n",
       " 'biken',\n",
       " 'lok',\n",
       " 'saekniotan',\n",
       " 'siolai',\n",
       " 'sabet',\n",
       " 'dik',\n",
       " 'thoramaisin',\n",
       " 'thilin',\n",
       " 'saek niotan',\n",
       " '',\n",
       " 'kai',\n",
       " '',\n",
       " 'phofinlai',\n",
       " '',\n",
       " 'on',\n",
       " 'miniam',\n",
       " 'wai',\n",
       " 'khonda',\n",
       " 'to',\n",
       " 'biam',\n",
       " 'khoen',\n",
       " 'lot',\n",
       " 'sai',\n",
       " 'thi',\n",
       " 'wokhado',\n",
       " 'ran',\n",
       " 'kam',\n",
       " 'toe',\n",
       " 'moksisinlin',\n",
       " 'sai',\n",
       " '',\n",
       " 'fit',\n",
       " 'mandin',\n",
       " 'nai',\n",
       " 'mason',\n",
       " 'chi',\n",
       " 'to',\n",
       " '',\n",
       " 'rinan',\n",
       " 'loi',\n",
       " 'khe',\n",
       " 'thimoni',\n",
       " 'leksandrai',\n",
       " 'boe',\n",
       " 'trawai',\n",
       " 'rai',\n",
       " 'poen',\n",
       " 'phi',\n",
       " 'baendai',\n",
       " 'lakhanalaemin',\n",
       " 'thoethenmen',\n",
       " 'fibian',\n",
       " 'phichi▁khoporechan',\n",
       " '',\n",
       " 'phoensotmaep',\n",
       " 'mai',\n",
       " '',\n",
       " 'nolai',\n",
       " 'toenet',\n",
       " 'mit',\n",
       " 'enthophairai',\n",
       " 'oes',\n",
       " 'doesonai',\n",
       " 'chenthai',\n",
       " 'khoelosorat',\n",
       " 'mandai',\n",
       " 'osai',\n",
       " 'tibodi',\n",
       " '',\n",
       " 'thi',\n",
       " 'thiria',\n",
       " 'wae',\n",
       " 'denai',\n",
       " 'drokrotsula',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'thaek',\n",
       " 'lai',\n",
       " '',\n",
       " '',\n",
       " 'rikhen',\n",
       " 'nai',\n",
       " 'phet',\n",
       " '',\n",
       " 'laendai',\n",
       " 'sai',\n",
       " 'ri',\n",
       " 'met',\n",
       " '',\n",
       " 'laendai',\n",
       " 'drochensanfai',\n",
       " 'okraem',\n",
       " 'phothalamat',\n",
       " 'liam',\n",
       " 'boekai']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "866fb522",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pred-ep5.txt\",'w',encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db052ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ground_truth.txt\",'w',encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1144ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
