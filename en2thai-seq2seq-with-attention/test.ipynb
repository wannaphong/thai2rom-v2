{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 23 20:03:18 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 511.69       Driver Version: 511.69       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   66C    P8     4W /  N/A |    561MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1824    C+G                                   N/A      |\n",
      "|    0   N/A  N/A     22608    C+G   ...t\\Teams\\current\\Teams.exe    N/A      |\n",
      "|    0   N/A  N/A     26120    C+G   ...llMobileConnectClient.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=''\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torchvision import transforms, utils\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "SEED = 0\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = os.path.join('..','dataset','cs')\n",
    "test_filepaths = os.path.join(path_dataset,'test.tsv')\n",
    "test_df = pd.read_csv(test_filepaths,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    input_texts = [str(i) for i in list(data_path['word'])]\n",
    "    target_texts = [str(i) for i in list(data_path['roman'])]\n",
    "    return target_texts,input_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_texts, test_target_texts = load_data(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define special characters\n",
    "UNK_token = '<UNK>'\n",
    "PAD_token = '<PAD>'\n",
    "START_token = '<start>'\n",
    "END_token = '<end>'\n",
    "MAX_LENGTH = 60\n",
    "\n",
    "class Language:\n",
    "    def __init__(self, name, is_input=False):\n",
    "        self.name = name\n",
    "        self.characters = set()\n",
    "        self.n_chars = 0\n",
    "        self.char2index = {}\n",
    "        self.index2char = {}\n",
    "\n",
    "        if is_input == True:\n",
    "            self.index2char = { 0: PAD_token, 1: UNK_token, 2: START_token, 3: END_token }\n",
    "            self.char2index = { ch:i for i, ch in self.index2char.items() } #reverse dictionary\n",
    "            self.n_chars = 4\n",
    "        else:\n",
    "            self.index2char = { 0: PAD_token, 1: START_token, 2: END_token }\n",
    "            self.char2index = { ch:i for i, ch in self.index2char.items() } #reverse dictionary\n",
    "            self.n_chars = 3\n",
    "\n",
    "    def addText(self, text):\n",
    "        for character in text:\n",
    "            self.addCharacter(character)\n",
    "    \n",
    "    def addCharacter(self, character):\n",
    "        if character not in self.char2index.keys():\n",
    "            self.char2index[character] = self.n_chars\n",
    "            self.index2char[self.n_chars] = character\n",
    "            self.n_chars += 1\n",
    "            \n",
    "            \n",
    "def indexesFromText(lang, text):\n",
    "    \"\"\"returns indexes for all character given the text in the specified language\"\"\"\n",
    "    return [lang.char2index[char] for char in text]\n",
    "\n",
    "def tensorFromText(lang, text):\n",
    "    \"\"\"construct a tensor given the text in the specified language\"\"\"\n",
    "    indexes = indexesFromText(lang, text)\n",
    "    indexes.append(lang.char2index[END_token])\n",
    "    \n",
    "    no_padded_seq_length = len(indexes) # Number of characters in the text (including <END> token)\n",
    "    # Add padding token to make all tensors in the same length\n",
    "    for i in range(len(indexes), MAX_LENGTH): # padding\n",
    "        indexes.append(lang.char2index[PAD_token])\n",
    "        \n",
    "    return torch.tensor(indexes, dtype=torch.long), no_padded_seq_length\n",
    "\n",
    "def filterPair(p1, p2):\n",
    "    \"\"\"filter for the pair the both texts has length less than `MAX_LENGTH`\"\"\"\n",
    "    return len(p1) < MAX_LENGTH and len(p2) < MAX_LENGTH\n",
    "\n",
    "def tensorsFromPair(pair, lang1, lang2):\n",
    "    \"\"\"construct two tensors from a pair of source and target text specified by source and target language\"\"\"\n",
    "    input_tensor, input_length = tensorFromText(lang1, pair[0])\n",
    "    target_tensor, target_length = tensorFromText(lang2, pair[1])\n",
    "    return input_tensor, target_tensor, input_length, target_length\n",
    "\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        input_text, target_text, lang_th, lang_th_romanized = sample['input_text'], sample['target_text'],                                                               sample['lang_th'], sample['lang_th_romanized']\n",
    "\n",
    "        input_tensor, target_tensor, input_length, target_length = tensorsFromPair([input_text, target_text], \n",
    "                                                                                   lang_th, \n",
    "                                                                                   lang_th_romanized)\n",
    "        \n",
    "        return {\n",
    "                'input_text': input_text,\n",
    "                'target_text': target_text,\n",
    "                'input_length': input_length,\n",
    "                'target_length': target_length,\n",
    "                'input_tensor': input_tensor,\n",
    "                'target_tensor': target_tensor\n",
    "               }\n",
    "    \n",
    "    \n",
    "class ThaiRomanizationDataset(Dataset):\n",
    "    \"\"\"Thai Romanization Dataset class\"\"\"\n",
    "    def __init__(self, \n",
    "                 data_path, \n",
    "                 transform=transforms.Compose([ ToTensor() ])):\n",
    "\n",
    "        input_texts, target_texts = load_data(data_path)\n",
    "        \n",
    "        self.input_texts = input_texts\n",
    "        self.target_texts = target_texts\n",
    "        self.transform = transform\n",
    "        self.lang_th = None\n",
    "        self.lang_th_romanized = None\n",
    "        self.counter = Counter()\n",
    "        self.pairs = []\n",
    "        self.prepareData()\n",
    "\n",
    "    def prepareData(self):\n",
    "        self.lang_th = Language('th', is_input=True)\n",
    "        self.lang_th_romanized = Language('th_romanized', is_input=False)\n",
    "        for i in range(len(self.input_texts)):\n",
    "            \n",
    "            input_text = str(self.input_texts[i])\n",
    "            target_text = str(self.target_texts[i])\n",
    "            \n",
    "            # Count the number of input and target sequences with length `x`\n",
    "            self.counter.update({ \n",
    "                                  'len_input_{}'.format(len(input_text)): 1, \n",
    "                                  'len_target_{}'.format(len(target_text)): 1 \n",
    "                                })\n",
    "            \n",
    "            if filterPair(input_text, target_text):\n",
    "                self.pairs.append((input_text, target_text))\n",
    "                self.lang_th.addText(input_text)\n",
    "                self.lang_th_romanized.addText(target_text)    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        sample = dict()\n",
    "        sample['input_text'] = self.pairs[idx][0]\n",
    "        sample['target_text'] = self.pairs[idx][1]\n",
    "        \n",
    "        sample['lang_th'] = self.lang_th\n",
    "        sample['lang_th_romanized'] = self.lang_th_romanized\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocabulary_size, embedding_size, hidden_size, dropout=0.5):\n",
    "        \"\"\"Constructor\"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.character_embedding = nn.Embedding(vocabulary_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_size, \n",
    "                            hidden_size=hidden_size // 2, \n",
    "                            bidirectional=True,\n",
    "                            batch_first=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def forward(self, sequences, sequences_lengths):\n",
    "        batch_size = sequences.size(0)\n",
    "        self.hidden = self.init_hidden(batch_size) # batch_size\n",
    "\n",
    "        # sequences :(batch_size, sequence_length=MAX_LENGTH)\n",
    "        # sequences_lengths: (batch_size)  # an 1-D indicating length of each sequence (excluded <PAD> token) in `seq`\n",
    "        \n",
    "        # 1. Firstly we sort `sequences_lengths` according to theirs values and keep list of indexes to perform sorting\n",
    "        sequences_lengths = np.sort(sequences_lengths)[::-1] # sort in ascending order and reverse it\n",
    "        index_sorted = np.argsort(-sequences_lengths) # use negation in sort in descending order\n",
    "        index_unsort = np.argsort(index_sorted) # to unsorted sequence\n",
    "        \n",
    "        \n",
    "        # 2. Then, we change position of sequence in `sequences` according to `index_sorted`\n",
    "        index_sorted = torch.from_numpy(index_sorted)\n",
    "        sequences = sequences.index_select(0, index_sorted)\n",
    "        \n",
    "        # 3. Feed to Embedding Layer\n",
    "        \n",
    "        sequences = self.character_embedding(sequences)\n",
    "        sequences = self.dropout(sequences)\n",
    "        \n",
    "#         print('sequences',sequences.size(), sequences)\n",
    "            \n",
    "        # 3. Use function: pack_padded_sequence to let LSTM packed input with same length at time step T together\n",
    "        \n",
    "        # Quick fix: Use seq_len.copy(), instead of seq_len to fix `Torch.from_numpy not support negative strides`\n",
    "        # ndarray.copy() will alocate new memory for numpy array which make it normal, I mean the stride is not negative any more.\n",
    "\n",
    "        sequences_packed = nn.utils.rnn.pack_padded_sequence(sequences,\n",
    "                                                             sequences_lengths.copy(),\n",
    "                                                             batch_first=True)\n",
    "#         print('sequences_packed', sequences_packed)\n",
    "\n",
    "        # 4. Feed to LSTM\n",
    "        sequences_output, self.hidden = self.lstm(sequences_packed, self.hidden)\n",
    "        \n",
    "        # 5. Unpack\n",
    "        sequences_output, _ = nn.utils.rnn.pad_packed_sequence(sequences_output, batch_first=True)\n",
    "\n",
    "        # 6. Un-sort by length\n",
    "        index_unsort = torch.from_numpy(index_unsort)\n",
    "        sequences_output = sequences_output.index_select(0, Variable(index_unsort))\n",
    "\n",
    "#         print('hidden shape', self.hidden[0].shape, self.hidden[0], self.hidden[1].shape, self.hidden[1])\n",
    "        return sequences_output, self.hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        h_0 = torch.zeros([2, batch_size, self.hidden_size // 2], requires_grad=True)\n",
    "        c_0 = torch.zeros([2, batch_size, self.hidden_size // 2], requires_grad=True)\n",
    "        \n",
    "        return (h_0, c_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "\n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.other = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs, mask):\n",
    "        # hidden: B x 1 x h ; \n",
    "        # encoder_outputs: B x S x h\n",
    "\n",
    "        # Calculate energies for each encoder output\n",
    "        if self.method == 'dot':\n",
    "            attn_energies = torch.bmm(encoder_outputs, hidden.transpose(1, 2)).squeeze(2)  # B x S\n",
    "        elif self.method == 'general':\n",
    "            attn_energies = self.attn(encoder_outputs.view(-1, encoder_outputs.size(-1)))  # (B * S) x h\n",
    "            attn_energies = torch.bmm(attn_energies.view(*encoder_outputs.size()),\n",
    "                                      hidden.transpose(1, 2)).squeeze(2)  # B x S\n",
    "        elif self.method == 'concat':\n",
    "            attn_energies = self.attn(\n",
    "                torch.cat((hidden.expand(*encoder_outputs.size()), encoder_outputs), 2))  # B x S x h\n",
    "            attn_energies = torch.bmm(attn_energies,\n",
    "                                      self.other.unsqueeze(0).expand(*hidden.size()).transpose(1, 2)).squeeze(2)\n",
    "\n",
    "        attn_energies = attn_energies.masked_fill(mask == 0, -1e10)\n",
    "\n",
    "        # Normalize energies to weights in range 0 to 1\n",
    "        return F.softmax(attn_energies, 1)\n",
    "\n",
    "class AttentionDecoder(nn.Module): \n",
    "    \n",
    "    def __init__(self, vocabulary_size, embedding_size, hidden_size, dropout=0.5):\n",
    "        \"\"\"Constructor\"\"\"\n",
    "        super(AttentionDecoder, self).__init__()\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.character_embedding = nn.Embedding(vocabulary_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_size + self.hidden_size,\n",
    "                            hidden_size=hidden_size,\n",
    "                            bidirectional=False,\n",
    "                            batch_first=True)\n",
    "        \n",
    "        self.attn = Attn(method=\"general\", hidden_size=self.hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size * 2, vocabulary_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        \n",
    "    def forward(self, input, last_hidden, last_context, encoder_outputs, mask):\n",
    "        \"\"\"\"Defines the forward computation of the decoder\"\"\"\n",
    "        # input: (B, 1) ,\n",
    "        # last_hidden: (num_layers * num_directions, B, hidden_dim)\n",
    "        # last_context: (B, 1, hidden_dim)\n",
    "        # encoder_outputs: (B, S, hidden_dim)\n",
    "        \n",
    "        embedded = self.character_embedding(input)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        # embedded: (batch_size, emb_dim)\n",
    "        rnn_input = torch.cat((embedded, last_context), 2)\n",
    "\n",
    "        output, hidden = self.lstm(rnn_input, last_hidden)        \n",
    "        attn_weights = self.attn(output, encoder_outputs, mask)  # B x S\n",
    "    \n",
    "        #  context = (B, 1, S) x (B, S, hidden_dim)\n",
    "        #  context = (B, 1, hidden_dim)\n",
    "        context = attn_weights.unsqueeze(1).bmm(encoder_outputs)  \n",
    "        \n",
    "        output = torch.cat((context.squeeze(1), output.squeeze(1)), 1)\n",
    "        output = self.linear(output)\n",
    "        \n",
    "        return output, hidden, context, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module): \n",
    "\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.pad_idx = 0\n",
    "\n",
    "        assert encoder.hidden_size == decoder.hidden_size\n",
    "    \n",
    "    def create_mask(self, source_seq):\n",
    "        mask = (source_seq != self.pad_idx)\n",
    "        return mask\n",
    "        \n",
    "  \n",
    "    def forward(self, source_seq, source_seq_len, target_seq, teacher_forcing_ratio = 0.5):\n",
    "        \"\"\"\n",
    "            Parameters:\n",
    "                - source_seq: (batch_size x MAX_LENGTH) \n",
    "                - source_seq_len: (batch_size x 1)\n",
    "                - target_seq: (batch_size x MAX_LENGTH)\n",
    "\n",
    "            Returns\n",
    "        \"\"\"\n",
    "        batch_size = source_seq.size(0)\n",
    "        start_token = char_to_ix[\"<start>\"]\n",
    "        end_token = char_to_ix[\"<end>\"]\n",
    "        max_len = MAX_LENGTH\n",
    "        target_vocab_size = self.decoder.vocabulary_size\n",
    "\n",
    "        # init a tensor to store decoder outputs\n",
    "        outputs = torch.zeros(max_len, batch_size, target_vocab_size)\n",
    "        \n",
    "        if target_seq is None:\n",
    "            assert teacher_forcing_ratio == 0, \"Must be zero during inference\"\n",
    "            inference = True\n",
    "        else:\n",
    "            inference = False\n",
    "\n",
    "    \n",
    "        # feed mini-batch source sequences into the `Encoder`\n",
    "        encoder_outputs, encoder_hidden = self.encoder(source_seq, source_seq_len)\n",
    "\n",
    "        # create a Tensor of first input for the decoder\n",
    "        decoder_input = torch.tensor([[start_token] * batch_size]).view(batch_size, 1)\n",
    "        \n",
    "        # Initiate decoder output as the last state encoder's hidden state\n",
    "        decoder_hidden_0 = torch.cat([encoder_hidden[0][0], encoder_hidden[0][1]], dim=1).unsqueeze(dim=0)\n",
    "        decoder_hidden_1 = torch.cat([encoder_hidden[1][0], encoder_hidden[1][1]], dim=1).unsqueeze(dim=0)\n",
    "        decoder_hidden = (decoder_hidden_0, decoder_hidden_1) # (hidden state, cell state)\n",
    "\n",
    "        # define a context vector\n",
    "        decoder_context = Variable(torch.zeros(encoder_outputs.size(0), encoder_outputs.size(2))).unsqueeze(1)\n",
    "        \n",
    "        max_source_len = encoder_outputs.size(1)\n",
    "        mask = self.create_mask(source_seq[:, 0:max_source_len])\n",
    "            \n",
    "       \n",
    "        for di in range(max_len):\n",
    "            decoder_output, decoder_hidden, decoder_context, attn_weights = self.decoder(decoder_input,\n",
    "                                                                                    decoder_hidden,\n",
    "                                                                                    decoder_context,\n",
    "                                                                                    encoder_outputs,\n",
    "                                                                                    mask)\n",
    "            # decoder_output: (batch_size, target_vocab_size)\n",
    "\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            outputs[di] = decoder_output\n",
    "    \n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "\n",
    "\n",
    "            decoder_input = target_seq[:, di].reshape(batch_size, 1) if teacher_force else topi.detach() \n",
    "\n",
    "            if inference and decoder_input == end_token:\n",
    "                return outputs[:di]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, text, char_2_ix, ix_2_char, target_char_to_ix, ix_to_target_char):\n",
    "    input_seq =  [ch for ch in text] +  ['<end>']\n",
    "    numericalized = [char_2_ix[ch] for ch in input_seq] \n",
    "    \n",
    "#     print('input ',numericalized)\n",
    "    sentence_length = [len(numericalized)]\n",
    "\n",
    "    tensor = torch.LongTensor(numericalized).view(1, -1) \n",
    "    \n",
    "#     print(tensor)\n",
    "    translation_tensor_logits = model(tensor, sentence_length, None, 0) \n",
    "#     print(translation_tensor_logits)\n",
    "    if translation_tensor_logits.size(0) == 0:\n",
    "        translation_indices = [0]\n",
    "        translation = ['<pad>']\n",
    "    else:\n",
    "        translation_tensor = torch.argmax(translation_tensor_logits.squeeze(1), 1).cpu().numpy()\n",
    "        translation_indices = [t for t in translation_tensor]\n",
    "        translation = [ix_to_target_char[t] for t in translation_tensor]\n",
    "    return ''.join(translation), translation_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    \n",
    "    data = torch.load(model_path)\n",
    "    \n",
    "    INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, ENC_DROPOUT = data['encoder_params']\n",
    "    OUTPUT_DIM, DEC_EMB_DIM, DEC_HID_DIM, DEC_DROPOUT = data['decoder_params']\n",
    "\n",
    "    \n",
    "    encoder = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM)\n",
    "    decoder = AttentionDecoder(OUTPUT_DIM, DEC_EMB_DIM, DEC_HID_DIM)\n",
    "\n",
    "    model = Seq2Seq(encoder, decoder)\n",
    "    \n",
    "    model.load_state_dict(data['model_state_dict'])\n",
    "    \n",
    "    \n",
    "    learning_rate = 0.001\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    optimizer.load_state_dict(data['optimizer_state_dict'])\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index = 0)\n",
    "\n",
    "    char_to_ix = data['char_to_ix']\n",
    "    ix_to_char = data['ix_to_char'] \n",
    "    target_char_to_ix = data['target_char_to_ix']\n",
    "    ix_to_target_char = data['ix_to_target_char']\n",
    "    \n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'optmizer': optimizer,\n",
    "        'char_to_ix': char_to_ix,\n",
    "        'ix_to_char' : ix_to_char,\n",
    "        'target_char_to_ix': target_char_to_ix,\n",
    "        'ix_to_target_char': ix_to_target_char\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=load_model(\"model/thai2rom-pytorch-5.attn.v6.best_epoch-5.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = data['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': Seq2Seq(\n",
       "   (encoder): Encoder(\n",
       "     (character_embedding): Embedding(40, 128)\n",
       "     (lstm): LSTM(128, 128, batch_first=True, bidirectional=True)\n",
       "     (dropout): Dropout(p=0.5, inplace=False)\n",
       "   )\n",
       "   (decoder): AttentionDecoder(\n",
       "     (character_embedding): Embedding(93, 128)\n",
       "     (lstm): LSTM(384, 256, batch_first=True)\n",
       "     (attn): Attn(\n",
       "       (attn): Linear(in_features=256, out_features=256, bias=True)\n",
       "     )\n",
       "     (linear): Linear(in_features=512, out_features=93, bias=True)\n",
       "     (dropout): Dropout(p=0.5, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'optmizer': Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     eps: 1e-08\n",
       "     lr: 0.001\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " 'char_to_ix': {'<PAD>': 0,\n",
       "  '<UNK>': 1,\n",
       "  '<start>': 2,\n",
       "  '<end>': 3,\n",
       "  'k': 4,\n",
       "  'a': 5,\n",
       "  's': 6,\n",
       "  'e': 7,\n",
       "  'm': 8,\n",
       "  ' ': 9,\n",
       "  'b': 10,\n",
       "  'u': 11,\n",
       "  'n': 12,\n",
       "  'h': 13,\n",
       "  'i': 14,\n",
       "  'r': 15,\n",
       "  'o': 16,\n",
       "  't': 17,\n",
       "  'p': 18,\n",
       "  'g': 19,\n",
       "  'w': 20,\n",
       "  'l': 21,\n",
       "  'd': 22,\n",
       "  'c': 23,\n",
       "  'y': 24,\n",
       "  'f': 25,\n",
       "  '1': 26,\n",
       "  '(': 27,\n",
       "  ')': 28,\n",
       "  '2': 29,\n",
       "  '5': 30,\n",
       "  '3': 31,\n",
       "  '6': 32,\n",
       "  '4': 33,\n",
       "  '7': 34,\n",
       "  '0': 35,\n",
       "  '!': 36,\n",
       "  '9': 37,\n",
       "  '8': 38,\n",
       "  '\"': 39,\n",
       "  'v': 4,\n",
       "  'x': 5,\n",
       "  'z': 6,\n",
       "  'é': 7,\n",
       "  'q': 8,\n",
       "  \"'\": 9,\n",
       "  'j': 10,\n",
       "  'ฺ': 11,\n",
       "  'è': 12,\n",
       "  '岸': 13,\n",
       "  '田': 14,\n",
       "  '文': 15,\n",
       "  '雄': 16,\n",
       "  '.': 17,\n",
       "  '–': 18},\n",
       " 'ix_to_char': {0: '<PAD>',\n",
       "  1: '<UNK>',\n",
       "  2: '<start>',\n",
       "  3: '<end>',\n",
       "  4: 'v',\n",
       "  5: 'x',\n",
       "  6: 'z',\n",
       "  7: 'é',\n",
       "  8: 'q',\n",
       "  9: \"'\",\n",
       "  10: 'j',\n",
       "  11: 'ฺ',\n",
       "  12: 'è',\n",
       "  13: '岸',\n",
       "  14: '田',\n",
       "  15: '文',\n",
       "  16: '雄',\n",
       "  17: '.',\n",
       "  18: '–',\n",
       "  19: 'g',\n",
       "  20: 'w',\n",
       "  21: 'l',\n",
       "  22: 'd',\n",
       "  23: 'c',\n",
       "  24: 'y',\n",
       "  25: 'f',\n",
       "  26: '1',\n",
       "  27: '(',\n",
       "  28: ')',\n",
       "  29: '2',\n",
       "  30: '5',\n",
       "  31: '3',\n",
       "  32: '6',\n",
       "  33: '4',\n",
       "  34: '7',\n",
       "  35: '0',\n",
       "  36: '!',\n",
       "  37: '9',\n",
       "  38: '8',\n",
       "  39: '\"'},\n",
       " 'target_char_to_ix': {'<PAD>': 0,\n",
       "  '<start>': 1,\n",
       "  '<end>': 2,\n",
       "  'เ': 3,\n",
       "  'ก': 4,\n",
       "  'ษ': 5,\n",
       "  'ม': 6,\n",
       "  ' ': 7,\n",
       "  'บ': 8,\n",
       "  'ุ': 9,\n",
       "  'ญ': 10,\n",
       "  'า': 11,\n",
       "  'ห': 12,\n",
       "  'ั': 13,\n",
       "  'น': 14,\n",
       "  'ิ': 15,\n",
       "  'โ': 16,\n",
       "  'ร': 17,\n",
       "  'ธ': 18,\n",
       "  'ศ': 19,\n",
       "  'ล': 20,\n",
       "  'พ': 21,\n",
       "  '่': 22,\n",
       "  'ท': 23,\n",
       "  'ย': 24,\n",
       "  '์': 25,\n",
       "  'ี': 26,\n",
       "  'ต': 27,\n",
       "  'อ': 28,\n",
       "  '็': 29,\n",
       "  'ง': 30,\n",
       "  'แ': 31,\n",
       "  'ซ': 32,\n",
       "  'ส': 33,\n",
       "  'ว': 34,\n",
       "  'ะ': 35,\n",
       "  'ำ': 36,\n",
       "  'ด': 37,\n",
       "  'จ': 38,\n",
       "  'ค': 39,\n",
       "  'ณ': 40,\n",
       "  'ฑ': 41,\n",
       "  'ึ': 42,\n",
       "  '้': 43,\n",
       "  'ู': 44,\n",
       "  'ฤ': 45,\n",
       "  'ฐ': 46,\n",
       "  'ข': 47,\n",
       "  'ฒ': 48,\n",
       "  'ฎ': 49,\n",
       "  'ป': 50,\n",
       "  'ไ': 51,\n",
       "  'ช': 52,\n",
       "  'ฏ': 53,\n",
       "  'ภ': 54,\n",
       "  'ฆ': 55,\n",
       "  'ฟ': 56,\n",
       "  'ฮ': 57,\n",
       "  'ื': 58,\n",
       "  'ผ': 59,\n",
       "  '๋': 60,\n",
       "  'ใ': 61,\n",
       "  '๊': 62,\n",
       "  'ถ': 63,\n",
       "  'ฌ': 64,\n",
       "  'ฉ': 65,\n",
       "  'ฝ': 66,\n",
       "  'ฬ': 67,\n",
       "  '.': 68,\n",
       "  'ฦ': 69,\n",
       "  '(': 70,\n",
       "  ')': 71,\n",
       "  'ฯ': 72,\n",
       "  '-': 73,\n",
       "  'ฃ': 74,\n",
       "  'ๆ': 75,\n",
       "  '2': 76,\n",
       "  'ๅ': 77,\n",
       "  'ฅ': 78,\n",
       "  'ฺ': 79,\n",
       "  'ํ': 80,\n",
       "  '5': 81,\n",
       "  '3': 82,\n",
       "  '6': 83,\n",
       "  '4': 84,\n",
       "  '7': 85,\n",
       "  '1': 86,\n",
       "  '0': 87,\n",
       "  '!': 88,\n",
       "  '9': 89,\n",
       "  '8': 90,\n",
       "  '\"': 91,\n",
       "  '๙': 92},\n",
       " 'ix_to_target_char': {0: '<PAD>',\n",
       "  1: '<start>',\n",
       "  2: '<end>',\n",
       "  3: 'เ',\n",
       "  4: 'ก',\n",
       "  5: 'ษ',\n",
       "  6: 'ม',\n",
       "  7: ' ',\n",
       "  8: 'บ',\n",
       "  9: 'ุ',\n",
       "  10: 'ญ',\n",
       "  11: 'า',\n",
       "  12: 'ห',\n",
       "  13: 'ั',\n",
       "  14: 'น',\n",
       "  15: 'ิ',\n",
       "  16: 'โ',\n",
       "  17: 'ร',\n",
       "  18: 'ธ',\n",
       "  19: 'ศ',\n",
       "  20: 'ล',\n",
       "  21: 'พ',\n",
       "  22: '่',\n",
       "  23: 'ท',\n",
       "  24: 'ย',\n",
       "  25: '์',\n",
       "  26: 'ี',\n",
       "  27: 'ต',\n",
       "  28: 'อ',\n",
       "  29: '็',\n",
       "  30: 'ง',\n",
       "  31: 'แ',\n",
       "  32: 'ซ',\n",
       "  33: 'ส',\n",
       "  34: 'ว',\n",
       "  35: 'ะ',\n",
       "  36: 'ำ',\n",
       "  37: 'ด',\n",
       "  38: 'จ',\n",
       "  39: 'ค',\n",
       "  40: 'ณ',\n",
       "  41: 'ฑ',\n",
       "  42: 'ึ',\n",
       "  43: '้',\n",
       "  44: 'ู',\n",
       "  45: 'ฤ',\n",
       "  46: 'ฐ',\n",
       "  47: 'ข',\n",
       "  48: 'ฒ',\n",
       "  49: 'ฎ',\n",
       "  50: 'ป',\n",
       "  51: 'ไ',\n",
       "  52: 'ช',\n",
       "  53: 'ฏ',\n",
       "  54: 'ภ',\n",
       "  55: 'ฆ',\n",
       "  56: 'ฟ',\n",
       "  57: 'ฮ',\n",
       "  58: 'ื',\n",
       "  59: 'ผ',\n",
       "  60: '๋',\n",
       "  61: 'ใ',\n",
       "  62: '๊',\n",
       "  63: 'ถ',\n",
       "  64: 'ฌ',\n",
       "  65: 'ฉ',\n",
       "  66: 'ฝ',\n",
       "  67: 'ฬ',\n",
       "  68: '.',\n",
       "  69: 'ฦ',\n",
       "  70: '(',\n",
       "  71: ')',\n",
       "  72: 'ฯ',\n",
       "  73: '-',\n",
       "  74: 'ฃ',\n",
       "  75: 'ๆ',\n",
       "  76: '2',\n",
       "  77: 'ๅ',\n",
       "  78: 'ฅ',\n",
       "  79: 'ฺ',\n",
       "  80: 'ํ',\n",
       "  81: '5',\n",
       "  82: '3',\n",
       "  83: '6',\n",
       "  84: '4',\n",
       "  85: '7',\n",
       "  86: '1',\n",
       "  87: '0',\n",
       "  88: '!',\n",
       "  89: '9',\n",
       "  90: '8',\n",
       "  91: '\"',\n",
       "  92: '๙'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_ix = data['char_to_ix']\n",
    "ix_to_char =  data['ix_to_char']\n",
    "target_char_to_ix = data['target_char_to_ix']\n",
    "ix_to_target_char = data['ix_to_target_char']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_2_ix=char_to_ix\n",
    "ix_2_char=ix_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (character_embedding): Embedding(40, 128)\n",
       "    (lstm): LSTM(128, 128, batch_first=True, bidirectional=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): AttentionDecoder(\n",
       "    (character_embedding): Embedding(93, 128)\n",
       "    (lstm): LSTM(384, 256, batch_first=True)\n",
       "    (attn): Attn(\n",
       "      (attn): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (linear): Linear(in_features=512, out_features=93, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text=\"mo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, indices = inference(model, input_text, char_2_ix, ix_2_char, target_char_to_ix, ix_to_target_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'มมอ'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.replace('<end>','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference2(model, text, char_2_ix, ix_2_char, target_char_to_ix, ix_to_target_char):\n",
    "    input_seq =  [ch for ch in text] +  ['<end>']\n",
    "    numericalized = [char_2_ix[ch] for ch in input_seq] \n",
    "    \n",
    "#     print('input ',numericalized)\n",
    "    sentence_length = [len(numericalized)]\n",
    "\n",
    "    tensor = torch.LongTensor(numericalized).view(1, -1) \n",
    "    return tensor, sentence_length, None, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run2(word):\n",
    "    return inference2(model, word, char_2_ix, ix_2_char, target_char_to_ix, ix_to_target_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(word):\n",
    "    prediction, indices = inference(model, word, char_2_ix, ix_2_char, target_char_to_ix, ix_to_target_char)\n",
    "    return prediction.replace('<end>','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[17, 16, 12, 17,  5, 12,  3]]), [7], None, 0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run2(\"tontan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ทอนตาน'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\"tontan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " '<UNK>': 1,\n",
       " '<start>': 2,\n",
       " '<end>': 3,\n",
       " 'k': 4,\n",
       " 'a': 5,\n",
       " 's': 6,\n",
       " 'e': 7,\n",
       " 'm': 8,\n",
       " ' ': 9,\n",
       " 'b': 10,\n",
       " 'u': 11,\n",
       " 'n': 12,\n",
       " 'h': 13,\n",
       " 'i': 14,\n",
       " 'r': 15,\n",
       " 'o': 16,\n",
       " 't': 17,\n",
       " 'p': 18,\n",
       " 'g': 19,\n",
       " 'w': 20,\n",
       " 'l': 21,\n",
       " 'd': 22,\n",
       " 'c': 23,\n",
       " 'y': 24,\n",
       " 'f': 25,\n",
       " '1': 26,\n",
       " '(': 27,\n",
       " ')': 28,\n",
       " '2': 29,\n",
       " '5': 30,\n",
       " '3': 31,\n",
       " '6': 32,\n",
       " '4': 33,\n",
       " '7': 34,\n",
       " '0': 35,\n",
       " '!': 36,\n",
       " '9': 37,\n",
       " '8': 38,\n",
       " '\"': 39,\n",
       " 'v': 4,\n",
       " 'x': 5,\n",
       " 'z': 6,\n",
       " 'é': 7,\n",
       " 'q': 8,\n",
       " \"'\": 9,\n",
       " 'j': 10,\n",
       " 'ฺ': 11,\n",
       " 'è': 12,\n",
       " '岸': 13,\n",
       " '田': 14,\n",
       " '文': 15,\n",
       " '雄': 16,\n",
       " '.': 17,\n",
       " '–': 18}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_2_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_input_texts, test_target_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4671d3acbee3453f8ad1897d01731023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=769.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred=[]\n",
    "model.eval()\n",
    "for i in tqdm(test_input_texts):\n",
    "    pred.append(run(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ก๊อปปี้',\n",
       " 'กิบบ์ไซต์',\n",
       " 'โกลด์',\n",
       " 'กอร์มาไนต์',\n",
       " 'แกรโทไนต์',\n",
       " 'แกลลอน',\n",
       " 'เกตเวย์',\n",
       " 'กิฟต์เซต',\n",
       " 'กลอโคเฟน',\n",
       " 'กรอสซูลาร์',\n",
       " 'กาลิเลโอกาลิเล',\n",
       " 'เกาต์',\n",
       " 'กิโลไซเกิล',\n",
       " 'การ์ด',\n",
       " 'กิมมิก',\n",
       " 'กรีนชีกต์',\n",
       " 'กัดมันไดต์',\n",
       " 'กลอโคไนต์',\n",
       " 'แก๊ง',\n",
       " 'เกอร์สดอร์ฟไฟต์',\n",
       " 'เค้ก',\n",
       " 'ไคลนอปไทโลไลต์',\n",
       " 'แคโมไมล์',\n",
       " 'คามีเลียน',\n",
       " 'ไคลฟ์',\n",
       " 'คอลเล็กชัน',\n",
       " 'คาร์ไมน์',\n",
       " 'ไคลโนเอนสตาไทต์',\n",
       " 'แคนทีน',\n",
       " 'คีเซไรต์',\n",
       " 'แคราเวย์',\n",
       " 'แคมเบอร์',\n",
       " 'เคอร์เซอร์',\n",
       " 'คอนโดมิเนียม',\n",
       " 'คริปโทเคอร์เรนซี',\n",
       " 'แคนต์',\n",
       " 'คอนเนลไลต์',\n",
       " 'คลอรีน',\n",
       " 'คาร์ป',\n",
       " 'คาร์เลทอไนต์',\n",
       " 'คาสเตอร์',\n",
       " 'คาลิปโซ',\n",
       " 'เคลอร์จี',\n",
       " 'คาลาไมน์',\n",
       " 'คอลลินไซต์',\n",
       " 'คุกกี้',\n",
       " 'คอนเดนเซอร์',\n",
       " 'แคลด',\n",
       " 'แคปิทัล',\n",
       " 'แคนต์',\n",
       " 'คีวี',\n",
       " 'แคนเซิล',\n",
       " 'คอโรนาไดต์',\n",
       " 'คริปโท',\n",
       " 'ควินิน',\n",
       " 'แคลิฟอร์เนีย',\n",
       " 'โคไซน์',\n",
       " 'คาเฟ',\n",
       " 'คอนกรีต',\n",
       " 'คาร์บอนไดออกไซด์',\n",
       " 'แคลิเบรต',\n",
       " 'คลีเช',\n",
       " 'คาราเมล',\n",
       " 'คลิป',\n",
       " 'แคลิเบอร์',\n",
       " 'เคเตอริง',\n",
       " 'คอนเทนต์',\n",
       " 'โครโมโซม',\n",
       " 'แคน',\n",
       " 'โควตา',\n",
       " 'คอฟฟี่',\n",
       " 'คิวไพรต์',\n",
       " 'โคโทไอต์',\n",
       " 'คลีก',\n",
       " 'โคฟ',\n",
       " 'ควอนตัม',\n",
       " 'คราฟต์',\n",
       " 'เคอร์ฟิว',\n",
       " 'แคปริคอร์นัส',\n",
       " 'คอเคซอยด์',\n",
       " 'คีเลต',\n",
       " 'คาร์เพ็ต',\n",
       " 'คาร์นิวัล',\n",
       " 'คอนแท็กต์เลนส์',\n",
       " 'โคต',\n",
       " 'แคนคริไนต์',\n",
       " 'คลอแรสโทไรต์',\n",
       " 'แคเช',\n",
       " 'คาเฟอิก',\n",
       " 'ครอนิเคิล',\n",
       " 'คริส',\n",
       " 'คิวอาร์โค้ด',\n",
       " 'คริโซไลต์',\n",
       " 'คอรันดัม',\n",
       " 'เคาน์เตอร์',\n",
       " 'คอมเม้นท์',\n",
       " 'คอนเน็กชัน',\n",
       " 'แคเทกอรี',\n",
       " 'แคลมเบอร์',\n",
       " 'คริโซคอลลา',\n",
       " 'คาร์บอนิก',\n",
       " 'คาแรกเตอร์',\n",
       " 'ไคลโนซอยไซต์',\n",
       " 'คอลแลบ',\n",
       " 'คลับ',\n",
       " 'โคลวีไซต์',\n",
       " 'คลาสซี',\n",
       " 'แคมแชฟต์',\n",
       " 'เคลม',\n",
       " 'แคราเมล',\n",
       " 'คอมพิวเตอร์',\n",
       " 'แคลง',\n",
       " 'คาร์ไบน์',\n",
       " 'แค็ปเชอร์',\n",
       " 'คัลเชอร์',\n",
       " 'คาสติง',\n",
       " 'ควอตซ์',\n",
       " 'คุร์นาคอไวต์',\n",
       " 'แคลาเวอไรต์',\n",
       " 'คาร์ดีโอ',\n",
       " 'เคลนเซอร์',\n",
       " 'ไคลโนฮิวไมต์',\n",
       " 'ไคล์',\n",
       " 'แจ็กเก็ต',\n",
       " 'โจ๊ก',\n",
       " 'จัมป์',\n",
       " 'จาโรไซต์',\n",
       " 'แจ็ก',\n",
       " 'เจเนอเรชัน',\n",
       " 'จััมป์',\n",
       " 'เจไดต์',\n",
       " 'แชร์',\n",
       " 'แชท',\n",
       " 'เชนจ์',\n",
       " 'เชอร์ชิลล์',\n",
       " 'เช็กลิสต์',\n",
       " 'เชเรียต',\n",
       " 'ชิก',\n",
       " 'ชังกี',\n",
       " 'เชอรี่',\n",
       " 'ชิลล์',\n",
       " 'เชร์รี',\n",
       " 'ชิมแปนซี',\n",
       " 'ชิกพี',\n",
       " 'ชิน',\n",
       " 'ชาร์จ',\n",
       " 'ชอร์ตโน้ต',\n",
       " 'เชลซี',\n",
       " 'ชิป',\n",
       " 'ชัฟ',\n",
       " 'แชริตี',\n",
       " 'เชียร์ลีดเดอร์',\n",
       " 'โชว์',\n",
       " 'เชอร์มาไคต์',\n",
       " 'ชานต์',\n",
       " 'ชิปมังก์',\n",
       " 'ชาโรไอต์',\n",
       " 'เชริช',\n",
       " 'ชัตนีย์',\n",
       " 'ชังก์',\n",
       " 'ชีป',\n",
       " 'ชาร์',\n",
       " 'ชัตดาวน์',\n",
       " 'ชอร์ไลต์',\n",
       " 'ชิลี',\n",
       " 'เชส',\n",
       " 'ซัปพอร์ต',\n",
       " 'โซลาริส',\n",
       " 'เซนติกรัม',\n",
       " 'เซอแรนไดต์',\n",
       " 'ซิมป์ซอไนต์',\n",
       " 'แซปไฟรีน',\n",
       " 'ไซซ์',\n",
       " 'เซนเซอร์',\n",
       " 'ซิงก์',\n",
       " 'เซ็กส์',\n",
       " 'ซิงเกิลมัม',\n",
       " 'ไซน์',\n",
       " 'ซูเปอร์มาร์เก็ต',\n",
       " 'เซนเชอรี',\n",
       " 'ซอสซูไรต์',\n",
       " 'เซียเรียล',\n",
       " 'แซนบอร์ไนต์',\n",
       " 'ซูเปอร์',\n",
       " 'ซูไทต์',\n",
       " 'ซาไลต์',\n",
       " 'ซีพียู',\n",
       " 'ซิทริน',\n",
       " 'ซินฮาไลต์',\n",
       " 'เซเลบ',\n",
       " 'ซิทคอม',\n",
       " 'ซิเทรต',\n",
       " 'ซิลลิมาไนต์',\n",
       " 'ไซเฟอร์',\n",
       " 'ไซเดอร์',\n",
       " 'ซีพิโอไลต์',\n",
       " 'โซเชียลเน็ตเวิร์ค',\n",
       " 'เซนติพีด',\n",
       " 'เซนาร์มอนไทต์',\n",
       " 'ซิงเกิล',\n",
       " 'ซิลิกา',\n",
       " 'เซอร์ไพรส์',\n",
       " 'ซินนามอน',\n",
       " 'ซิลไวต์',\n",
       " 'เซรามิก',\n",
       " 'เซลฟี่',\n",
       " 'ซาวอไรต์',\n",
       " 'ซามาร์สไกต์',\n",
       " 'ซาร์ด',\n",
       " 'ซีไอเอ',\n",
       " 'ซิป์เพไอต์',\n",
       " 'เซอร์เคิล',\n",
       " 'เซ็กซ์',\n",
       " 'โซนี่',\n",
       " 'ซิเคดา',\n",
       " 'เซอร์เคเดียน',\n",
       " 'โซโนตไลต์',\n",
       " 'เซฟ',\n",
       " 'ซิเดอไรต์',\n",
       " 'ซัน',\n",
       " 'ซีเลีย',\n",
       " 'โซเดียม',\n",
       " 'ไซลินไดรต์',\n",
       " 'เดเบียน',\n",
       " 'ดอว์ซอไนต์',\n",
       " 'ดราม่า',\n",
       " 'แดแรปสไกต์',\n",
       " 'เดซิลิตร',\n",
       " 'เดบิวต์',\n",
       " 'ดิลิเวอรี',\n",
       " 'ดีพ เลิร์นนิง',\n",
       " 'ไดนาโม',\n",
       " 'ดัชเชส',\n",
       " 'แดนบูไรต์',\n",
       " 'แดดดี',\n",
       " 'ดรอป',\n",
       " 'แดนซ์',\n",
       " 'ดานซ์',\n",
       " 'เดลล์',\n",
       " 'ดุบเนียม',\n",
       " 'เดอะเดลีเมลล์',\n",
       " 'ไดแซ็กคาไรด์',\n",
       " 'ดีปเลิร์นนิง',\n",
       " 'ดันแดไซต์',\n",
       " 'ดิไซน์',\n",
       " 'ตริโปลี',\n",
       " 'ตอร์ปิโด',\n",
       " 'แทรฟฟิก',\n",
       " 'แทรกเตอร์',\n",
       " 'ทองคำ',\n",
       " 'ทอไรต์',\n",
       " 'ไทซอไนต์',\n",
       " 'เทคนิค',\n",
       " 'เทกโอเวอร์',\n",
       " 'โทนี่',\n",
       " 'ไทรโคลแซน',\n",
       " 'เทรุกไกต์',\n",
       " 'เทรลเลอร์',\n",
       " 'ทีม',\n",
       " 'เทคนีเชียม',\n",
       " 'เทคนิค',\n",
       " 'ทัวริสต์',\n",
       " 'ทินักไซต์',\n",
       " 'ทักซีโด',\n",
       " 'ทอมซอไนต์',\n",
       " 'ไทรเซราท็อปส์',\n",
       " 'ทูเลียม',\n",
       " 'ไททาโนแมกนีไทต์',\n",
       " 'ทริป',\n",
       " 'แท็ก',\n",
       " 'ทาวน์เฮาส์',\n",
       " 'เทอร์คอยส์',\n",
       " 'แทนทาไลต์',\n",
       " 'ทอฟฟี่',\n",
       " 'ทอม',\n",
       " 'นอร์ทอีสต์',\n",
       " 'โน๊ตบุ๊ก',\n",
       " 'นิกโคไลต์',\n",
       " 'นอจยาไกต์',\n",
       " 'นีออน',\n",
       " 'ไนโอเบียม',\n",
       " 'นาซ่า',\n",
       " 'เนตบอล',\n",
       " 'นาห์โคไลต์',\n",
       " 'โนวาคิวไลต์',\n",
       " 'ไนต์คลับ',\n",
       " 'เนกเคดไบค์',\n",
       " 'นาซา',\n",
       " 'เนเชอร์สมูท',\n",
       " 'นอร์ทูไพต์',\n",
       " 'บุลรัช',\n",
       " 'โบลต์วูไดต์',\n",
       " 'บาร์เรล',\n",
       " 'บิโลว์',\n",
       " 'บิสกิต',\n",
       " 'บัลบัส',\n",
       " 'บีสโตร',\n",
       " 'บังเกิล',\n",
       " 'บิแดซเซิล',\n",
       " 'บาร์เบเรียน',\n",
       " 'บิวตี',\n",
       " 'บักกิต',\n",
       " 'เบลนด์',\n",
       " 'บลัฟ',\n",
       " 'บุตต์เจนแบไคต์',\n",
       " 'บ็อตทอม',\n",
       " 'เบรก',\n",
       " 'แบลสต์',\n",
       " 'โบกัส',\n",
       " 'เบเนดิกต์',\n",
       " 'เบ็ต',\n",
       " 'บิแวร์',\n",
       " 'บิตแม็ป',\n",
       " 'บ็อนบ็อน',\n",
       " 'แบ็ก',\n",
       " 'บิฮีมอท',\n",
       " 'บาร์มบี',\n",
       " 'บรูม',\n",
       " 'เบร์',\n",
       " 'เบซิน',\n",
       " 'บอยคอต',\n",
       " 'โบนีโต',\n",
       " 'บอยเฟรนด์',\n",
       " 'บล็อกโคลี่',\n",
       " 'บีฟ',\n",
       " 'บาริสตา',\n",
       " 'บัลบ์',\n",
       " 'โบว์ลินไกต์',\n",
       " 'บาร์น',\n",
       " 'บอย',\n",
       " 'บาร์ฟ',\n",
       " 'บลอบ',\n",
       " 'บีน',\n",
       " 'แบปทิซึม',\n",
       " 'แบ็ตเทิล',\n",
       " 'แบรส',\n",
       " 'โบรเชนไทต์',\n",
       " 'เบิร์นเอาต์',\n",
       " 'บลัดสโตน',\n",
       " 'เบลบอย',\n",
       " 'บิกิทาไอต์',\n",
       " 'บลีช',\n",
       " 'เบลนช์',\n",
       " 'บรอว์น',\n",
       " 'บรูเวอร์',\n",
       " 'เบราว์เซอร์',\n",
       " 'แบงเกิล',\n",
       " 'แบนโจ',\n",
       " 'เบิร์ป',\n",
       " 'แบนแดนนา',\n",
       " 'บริกันทีน',\n",
       " 'บัสต์',\n",
       " 'เบอร์ตี้',\n",
       " 'บลันต์',\n",
       " 'บีเทิล',\n",
       " 'แบนน็อก',\n",
       " 'บัลจ์',\n",
       " 'บรูม',\n",
       " 'บอยล์',\n",
       " 'บิลเลียด',\n",
       " 'บาซิลลัส',\n",
       " 'บรอด',\n",
       " 'แบ็กดร็อป',\n",
       " 'บลาสต์',\n",
       " 'บุลด็อก',\n",
       " 'ไบโพลาร์',\n",
       " 'บีคอน',\n",
       " 'แบ็ปทิซึม',\n",
       " 'บอดีการ์ด',\n",
       " 'แบรีออนิกซ์',\n",
       " 'บาร์บิคิว',\n",
       " 'แบดมินตัน',\n",
       " 'ไบรด์',\n",
       " 'แบล็กเบอร์รี',\n",
       " 'บอมแบสติก',\n",
       " 'บิลด์อัป',\n",
       " 'บรูเนต',\n",
       " 'บอลซา',\n",
       " 'บริกันด์',\n",
       " 'บร็อคโคลี่',\n",
       " 'เบสิก',\n",
       " 'บัสเตอร์',\n",
       " 'บรีด',\n",
       " 'เบิสต์',\n",
       " 'บลอนด์',\n",
       " 'บัดจิต',\n",
       " 'บัก',\n",
       " 'เบอร์แทรนไดต์',\n",
       " 'เบล',\n",
       " 'โบฮีเมียน',\n",
       " 'เบอร์ซาร์',\n",
       " 'บิสมูทิไนต์',\n",
       " 'บาร์บีคิว',\n",
       " 'บิวเรตต์',\n",
       " 'บรูเออร์',\n",
       " 'บุลโดซเซอร์',\n",
       " 'บรุก',\n",
       " 'บองโก',\n",
       " 'บาลซี',\n",
       " 'บริสก์',\n",
       " 'แบส',\n",
       " 'บันจีจัมป์',\n",
       " 'บรอนเซอร์',\n",
       " 'บลูเบร์รี',\n",
       " 'บอแรกซ์',\n",
       " 'ไบรเทน',\n",
       " 'บาย',\n",
       " 'บัฟฟาโล',\n",
       " 'เบิร์นเอาต์',\n",
       " 'บอร์ไนต์',\n",
       " 'บีต',\n",
       " 'เบลนเดอร์',\n",
       " 'บัลลิสติก',\n",
       " 'ไบโอดาตา',\n",
       " 'เบสต์เซลเลอร์',\n",
       " 'บลิป',\n",
       " 'บีบอป',\n",
       " 'บินต์',\n",
       " 'เบนิดิกต์',\n",
       " 'บรี',\n",
       " 'บล็อกเกอร์',\n",
       " 'แบ็ต',\n",
       " 'บรูว์',\n",
       " 'บิล',\n",
       " 'เบอร์เดนไทต์',\n",
       " 'บราวอยต์',\n",
       " 'บะนอฟฟี',\n",
       " 'เบิร์ช',\n",
       " 'บีก',\n",
       " 'แปซิฟิกไพพ์',\n",
       " 'เป็ปซี่',\n",
       " 'ปลาสเตอร์',\n",
       " 'โปรโมท',\n",
       " 'ไปรเวต',\n",
       " 'โปรแกรม',\n",
       " 'ปาล์ม',\n",
       " 'โปรแกรมเมอร์',\n",
       " 'ไพไนต์',\n",
       " 'พิทบูล',\n",
       " 'พาร์เซก',\n",
       " 'แพลตฟอร์ม',\n",
       " 'โพรโทไทป์',\n",
       " 'พรูน',\n",
       " 'พิตบูล',\n",
       " 'โพรเจกเตอร์',\n",
       " 'แพกโนไลต์',\n",
       " 'ไพรอกซีน',\n",
       " 'โพรโตไทป์',\n",
       " 'พานาโซนิค',\n",
       " 'โพลีเอสเตอร์',\n",
       " 'พอร์ตแลนไดต์',\n",
       " 'พาร์กาไซต์',\n",
       " 'พรูสไทต์',\n",
       " 'โพส',\n",
       " 'ไพรเวต',\n",
       " 'พีระมิด',\n",
       " 'พลัม',\n",
       " 'แพคเกจ',\n",
       " 'เพอร์ไทต์',\n",
       " 'พรีเซนต์',\n",
       " 'แพ็กเกจ',\n",
       " 'พลูออต',\n",
       " 'โพรมิเทียม',\n",
       " 'พรีเซ้นท์',\n",
       " 'แพลทินัม',\n",
       " 'แพลจิโอเคลส',\n",
       " 'โพรโมชัน',\n",
       " 'พลวง',\n",
       " 'ไพธอน',\n",
       " 'พิตบูลล์',\n",
       " 'พิกเชอร์',\n",
       " 'พิกโนมิเตอร์',\n",
       " 'พอลิเบไซต์',\n",
       " 'เพทาไลต์',\n",
       " 'แพล็ตฟอร์ม',\n",
       " 'ฟอนต์',\n",
       " 'ฟาสต์ฟูด',\n",
       " 'ฟาร์มาซูทิคัล',\n",
       " 'เฟสบุ๊ก',\n",
       " 'ฟีเชอร์',\n",
       " 'แฟชั่น',\n",
       " 'ฟุต',\n",
       " 'ไฟแนนซ์',\n",
       " 'ไฟเออร์',\n",
       " 'ฟรุตเค้ก',\n",
       " 'ฟอสฟอไรต์',\n",
       " 'แฟลกซ์',\n",
       " 'ฟิกซ์',\n",
       " 'แฟมิลี',\n",
       " 'ฟอร์กลิฟต์',\n",
       " 'เฟสบุ๊ค',\n",
       " 'ฟลูต',\n",
       " 'แฟรนไชส์',\n",
       " 'ฟลูออรีน',\n",
       " 'ไฟรเบอร์ไกต์',\n",
       " 'ฟิลเตอร์',\n",
       " 'เฟอร์กูซอไนต์',\n",
       " 'ฟรักโทส',\n",
       " 'ฟอสฟอรัส',\n",
       " 'ฟังก์ชัน',\n",
       " 'มอเซลแลนดส์เบอร์ไกต์',\n",
       " 'มาริโอ้',\n",
       " 'โมลิบดีไนต์',\n",
       " 'เมลิเฟน',\n",
       " 'แมสก์',\n",
       " 'มอร์แกไนต์',\n",
       " 'มัก',\n",
       " 'มิลเลอร์ไรต์',\n",
       " 'เมาท์',\n",
       " 'เมทิลแอลกอฮอล์',\n",
       " 'เมทาเเองโคลีไอต์',\n",
       " 'โมเลกุล',\n",
       " 'มิวสิก',\n",
       " 'ไมโครคอมพิวเตอร์',\n",
       " 'มาร์ค',\n",
       " 'มอลดาไวต์',\n",
       " 'มาร์เกต',\n",
       " 'มากาเร็ท',\n",
       " 'มีเทน',\n",
       " 'มาสก์',\n",
       " 'โมเสก',\n",
       " 'แมกซีซี',\n",
       " 'แมลาคอน',\n",
       " 'มัมมี่',\n",
       " 'มอนิเตอร์',\n",
       " 'แมกนีไซต์',\n",
       " 'มินา',\n",
       " 'มอลโทส',\n",
       " 'ไมครอน',\n",
       " 'เมลิไลต์',\n",
       " 'มิเมทีน',\n",
       " 'มาลาไคต์',\n",
       " 'เมาเชอร์ไรต์',\n",
       " 'แมงกาโนโซต์',\n",
       " 'มิลลิไซต์',\n",
       " 'มัฟฟินเรซินเค้ก',\n",
       " 'ไมโครซอฟต์',\n",
       " 'เยซู',\n",
       " 'ยูเดียไลต์',\n",
       " 'ยูเนี่ยน เพาเวอร์',\n",
       " 'แยม',\n",
       " 'ยูแรโนเฟน',\n",
       " 'เยลลี่',\n",
       " 'ยิปซี',\n",
       " 'ยูคริปไทต์',\n",
       " 'ยีลด์',\n",
       " 'รีไวนด์',\n",
       " 'รอยเตอร์',\n",
       " 'รีอัลการ์',\n",
       " 'รูทีเนียม',\n",
       " 'รีวิว',\n",
       " 'รีโมท',\n",
       " 'ริสต์',\n",
       " 'แรนซัมแวร์',\n",
       " 'ราสป์เบอร์รี',\n",
       " 'ริโมตคอนโทรล',\n",
       " 'เรินต์เกเนียม',\n",
       " 'รูบี้',\n",
       " 'โรบินสัน',\n",
       " 'รูอิน',\n",
       " 'โรบ็อต',\n",
       " 'เรดาร์',\n",
       " 'โรเดียม',\n",
       " 'ลิปซิงก์',\n",
       " 'เลอโนโว',\n",
       " 'เลอชาเทเลียไรต์',\n",
       " 'ล็อกดาวน์',\n",
       " 'ลูทีเชียม',\n",
       " 'โลชัน',\n",
       " 'ไลโอพลัวโรดอน',\n",
       " 'ลูสพารตส์',\n",
       " 'ลอเรนเซไนต์',\n",
       " 'ลอการิทึม',\n",
       " 'ลาเต้',\n",
       " 'ลิปบาล์ม',\n",
       " 'แล็บท็อป',\n",
       " 'โลวีไอต์',\n",
       " 'แลนด์มาร์ก',\n",
       " 'ลอนเชอร์',\n",
       " 'แลบราโดไรต์',\n",
       " 'ลิฟ',\n",
       " 'ลัดเลไมต์',\n",
       " 'ลิทิโอฟิไลต์',\n",
       " 'ไลซาร์ไดต์',\n",
       " 'เวอร์แนไดต์',\n",
       " 'วอร์ม',\n",
       " 'วินเนอร์กรุ๊ป เอ็นเตอร์ไพรซ์',\n",
       " 'วิตามินบี 1',\n",
       " 'วอลูม',\n",
       " 'วิลอซิแร็ปเตอร์',\n",
       " 'ไวแทลิตี',\n",
       " 'วิดีโอคอล',\n",
       " 'เวกเตอร์',\n",
       " 'วอลเพอร์ไจต์',\n",
       " 'วินโดวส์เอ็กซ์พี',\n",
       " 'วาเนเดียม',\n",
       " 'เวเวลไลต์',\n",
       " 'วิสตา',\n",
       " 'วันเดย์',\n",
       " 'วอตส์แอปป์',\n",
       " 'วิเวียไนต์',\n",
       " 'เวาเชอร์',\n",
       " 'ไวราไคต์',\n",
       " 'เว็บเพจ',\n",
       " 'เวเลนซี',\n",
       " 'เวิร์กช็อป',\n",
       " 'วูสไทต์',\n",
       " 'วอลเลย์บอล',\n",
       " 'สแกนเนอร์',\n",
       " 'สตีฟ จ็อบส์',\n",
       " 'สแตนด์',\n",
       " 'เสิร์ฟ',\n",
       " 'สะวันนา',\n",
       " 'สตัสส์เฟอร์ไทต์',\n",
       " 'สเตซี่',\n",
       " 'สเตนเลส',\n",
       " 'สเตจ',\n",
       " 'สแปม',\n",
       " 'สตรีมมิ่ง',\n",
       " 'สปอตไลต์',\n",
       " 'สตรอว์เบอร์รี่',\n",
       " 'สป็อต',\n",
       " 'สตอโรไลต์',\n",
       " 'สตาฟ',\n",
       " 'สเมกไทต์',\n",
       " 'สเต็ป',\n",
       " 'สเกต',\n",
       " 'สปินเอาต์',\n",
       " 'สไปโนซอรัส',\n",
       " 'สตรีตฟูด',\n",
       " 'สตรอนเชียไนต์',\n",
       " 'สคริปต์',\n",
       " 'สตาร์',\n",
       " 'สมิท',\n",
       " 'สต๊อก',\n",
       " 'สแปนโกไลต์',\n",
       " 'สเวตเตอร์',\n",
       " 'สไตลิสต์',\n",
       " 'สไกป์',\n",
       " 'สมาร์ต',\n",
       " 'หลุยส์',\n",
       " 'อินเดอไรต์',\n",
       " 'เอริด',\n",
       " 'ไอศกรีม',\n",
       " 'อะเกต',\n",
       " 'เอ็นอาร์ อินสแตนท์ โปรดิวซ์',\n",
       " 'อะเมริเซียม',\n",
       " 'โอเอซิส',\n",
       " 'อาร์เมอร์',\n",
       " 'โอเปร่า',\n",
       " 'ไอโฟน',\n",
       " 'อีเมล',\n",
       " 'ออกไซด์',\n",
       " 'โอ๊ต',\n",
       " 'อะเวนจูรีน',\n",
       " 'แอกเนส',\n",
       " 'เอ็มพีสาม',\n",
       " 'อาร์ต',\n",
       " 'แอฟเตอร์',\n",
       " 'อิเล็กทรอนิกส์',\n",
       " 'แอ็กเคานต์',\n",
       " 'เอมมอนไซต์',\n",
       " 'เอสซีบี',\n",
       " 'ออร์แกนิค',\n",
       " 'ไอโอดีน',\n",
       " 'แอลไพน์',\n",
       " 'แอ็กซิเดนต์',\n",
       " 'อะแควเรียม',\n",
       " 'แอกทิเนียม',\n",
       " 'อีริไทรต์',\n",
       " 'ไอแพด',\n",
       " 'อินเดอร์บอไรต์',\n",
       " 'โอนิกซ์',\n",
       " 'แอบิเกล',\n",
       " 'แอนะล็อก',\n",
       " 'ไอแซกนิวตัน',\n",
       " 'อิกซิโอไลต์',\n",
       " 'อลิซาเบธ',\n",
       " 'แอดดิกต์',\n",
       " 'อีริโทรไมซิน',\n",
       " 'อะเซทิลีน',\n",
       " 'ไอแซค นิวตัน',\n",
       " 'โอดีเอฟ',\n",
       " 'อีนาร์ไกต์',\n",
       " 'อะลาบาสเตอร์',\n",
       " 'อะโพฟิลไลต์',\n",
       " 'เอไอเอ',\n",
       " 'ออล',\n",
       " 'อะลูมิเนียม',\n",
       " 'โอเทไวต์',\n",
       " 'อนาคอนดา',\n",
       " 'ออตโต',\n",
       " 'เออร์เบียม',\n",
       " 'ออราเคิล',\n",
       " 'อัพโหลด',\n",
       " 'เอฟีไซต์',\n",
       " 'ไอที',\n",
       " 'แอโวคาโด',\n",
       " 'เอเมอรัลด์',\n",
       " 'อะแมลกัม',\n",
       " 'เอดิเตอร์',\n",
       " 'อะม็อกซิซิลลิน',\n",
       " 'อะนาลไซม์',\n",
       " 'อเดลล์',\n",
       " 'ออฟฟิศ',\n",
       " 'แอลมันดีน',\n",
       " 'อีริโอไนต์',\n",
       " 'แอมะซอน',\n",
       " 'อะแพชี',\n",
       " 'ออโต',\n",
       " 'โอปอ',\n",
       " 'อะดรีนัล',\n",
       " 'แอลลอย',\n",
       " 'เอ็มเค',\n",
       " 'แอนทิโมนี',\n",
       " 'อะเลกซานไดรต์',\n",
       " 'แอมเบอร์',\n",
       " 'อัลตร้าไวด์',\n",
       " 'อีจิไรต์',\n",
       " 'แอปเปิ้ล',\n",
       " 'ไอพี',\n",
       " 'อะลาแบนไดต์',\n",
       " 'แอลคานอแลมีนส์',\n",
       " 'เอนเทอร์เทนเมนต์',\n",
       " 'แอมฟิเบียน',\n",
       " 'เอ็มพีจี คอร์ปอเรชั่น',\n",
       " 'เอกซเรย์',\n",
       " 'โอเพิ่นสตรีทแมป',\n",
       " 'แอกไมต์',\n",
       " 'อะไรส์',\n",
       " 'อาร์เซโนไลต์',\n",
       " 'อินเตอร์เน็ต',\n",
       " 'แอดมิต',\n",
       " 'อาร์เจนโทไพไรต์',\n",
       " 'ไอโอเอส',\n",
       " 'แอนเดอร์ซอไนต์',\n",
       " 'อาร์เจนไทต์',\n",
       " 'แองเคอโลซอรัส',\n",
       " 'แอลมันไดต์',\n",
       " 'ไอโอไซต์',\n",
       " 'แอนติบอดี',\n",
       " 'อะโครไอต์',\n",
       " 'เฮลที',\n",
       " 'ฮิสทีเรีย',\n",
       " 'ฮาร์ดแวร์',\n",
       " 'ฮิดเดไนต์',\n",
       " 'ไฮโดรกรอสซูลาร์',\n",
       " 'เฮลท์',\n",
       " 'เฮิรตซ์',\n",
       " 'ไฮดรา',\n",
       " 'แฮชแทก',\n",
       " 'ฮาวไลต์',\n",
       " 'แฮร์รี่ เคน',\n",
       " 'ฮาห์เนียม',\n",
       " 'เฮอริเคน',\n",
       " 'ฮอยไนต์',\n",
       " 'โฮมเพจ',\n",
       " 'โฮเต็ล',\n",
       " 'ฮิวแลนไดต์',\n",
       " 'แฮงไซต์',\n",
       " 'แฮร์รี่',\n",
       " 'แฮนด์เมด',\n",
       " 'ฮาร์ดิสโทไนต์',\n",
       " 'ฮอลแลนไดต์',\n",
       " 'ไฮโดรเจนซัลไฟด์',\n",
       " 'ฮอโลแกรม',\n",
       " 'ไฮโพทาลามัส',\n",
       " 'ฮีเลียม',\n",
       " 'เฮเดนเบอร์ไกต์']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jiwer import cer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7959082659627125"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cer(test_target_texts,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['็อปี',\n",
       " 'ิิบบซต์',\n",
       " 'โกลด์',\n",
       " 'ออร์มาไนต์ต์ต์ต์ต์ต์ต์',\n",
       " 'รโทไนต์ต์ต์ต์ต์ต์',\n",
       " 'ัาลลอน',\n",
       " 'าก',\n",
       " '6ิฟ',\n",
       " 'ลลูโค',\n",
       " 'รอส',\n",
       " 'าาลิ',\n",
       " 'ะอ๊ต',\n",
       " 'ิิโลไค',\n",
       " 'คคร์ด',\n",
       " 'ิิมมมิก์',\n",
       " 'รี',\n",
       " 'ููดมานไดต์ต์ต์ต์ต์',\n",
       " 'ลลอโคไนต์ต์ต์ต์ต์ต์',\n",
       " 'าางก์',\n",
       " 'ฤกอร์ดดอร์ฟไฟต์ต์ต์ต์ต์ต์ต์ต์ต์ต',\n",
       " 'คคก',\n",
       " 'คลินอปิโลไลต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'ชคมมมิล',\n",
       " 'ชชมม',\n",
       " 'ชลิก',\n",
       " 'ะอล',\n",
       " 'คาร์มิน',\n",
       " 'คลิ',\n",
       " 'แคน',\n",
       " 'วี',\n",
       " 'คาราไวย์',\n",
       " 'ำคม',\n",
       " 'ุัรร์ซออร์',\n",
       " 'ะอนโดมินียมม',\n",
       " 'คริปโทอรรนซี',\n",
       " 'าคนต์',\n",
       " 'ะอน',\n",
       " 'คลอร์ไรน',\n",
       " 'คาร์ปป',\n",
       " 'คาร์',\n",
       " 'คาสตออร์',\n",
       " 'คคลิปซอ',\n",
       " 'คลลอร์',\n",
       " 'ะคลามิน',\n",
       " 'ะอลลินไซต์ต์ต์ต์ต์ต์ต์',\n",
       " 'ะคอกีี',\n",
       " 'ะอน',\n",
       " 'าคลด์',\n",
       " 'าคปิตาล์',\n",
       " 'ๆานต์ต์ต์ต์',\n",
       " 'วิวิ',\n",
       " 'าคน',\n",
       " 'ะอโรนาไดต์ต์ต์ต์ต์ต์ต์',\n",
       " 'คริปโต',\n",
       " 'ุมยนนน',\n",
       " 'คคลิฟอร์',\n",
       " 'โคซิน',\n",
       " 'ะคฟฟ',\n",
       " 'ะอน',\n",
       " 'าาร์บอนดิไไอด์',\n",
       " 'าคลิบราต',\n",
       " 'ชลิก',\n",
       " 'คครา',\n",
       " 'อลิป์',\n",
       " 'าคลิบร์',\n",
       " 'าค',\n",
       " 'ะอน',\n",
       " 'โครโมซอม',\n",
       " 'ๆคน์',\n",
       " 'มัอตา',\n",
       " 'ะอฟฟฟ',\n",
       " 'ุคปรไรต์',\n",
       " 'ะอโทไตต์',\n",
       " 'ชลิม',\n",
       " 'โคก',\n",
       " 'มันตัม',\n",
       " 'คราฟต์',\n",
       " 'ัคร์',\n",
       " 'คาปริโคร์นัส์',\n",
       " 'ะคอแคสอิด์',\n",
       " 'ชชลาต',\n",
       " 'คาร์',\n",
       " 'คาร์นิกาล์',\n",
       " 'คอนทาส',\n",
       " 'รคอต',\n",
       " 'คคน',\n",
       " 'คลอราสโทรไลต์ต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'าคชชต',\n",
       " 'าคฟฟีย',\n",
       " 'ครอนิกล์',\n",
       " 'าคริส์',\n",
       " 'ออร์โคดด',\n",
       " 'คริโซไลต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'ะอร์นดัม์',\n",
       " 'ะคอน',\n",
       " 'ะอม',\n",
       " 'ะอน',\n",
       " 'คคโทโกรี',\n",
       " 'คลาม',\n",
       " 'คริโซโอลลา์',\n",
       " 'คาร์บอนิก์',\n",
       " 'ชชรา',\n",
       " 'ิลิโนซอไซต์ต์ต์ต์ต์',\n",
       " 'ะอลลาบ',\n",
       " 'ัคล็บบ',\n",
       " 'ะอลววไซต์ต์ต์ต์ต์ต์',\n",
       " 'คลลสซี',\n",
       " 'ำคมมาฟต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'คลลมม',\n",
       " 'คครา',\n",
       " 'ะอมปู',\n",
       " 'คลลง',\n",
       " 'คาร์บิน',\n",
       " 'อคป',\n",
       " 'ุคล',\n",
       " 'คคสติง',\n",
       " 'มัร์ตส',\n",
       " 'ุุรร์นาโกไไไตต์ต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'คคลา',\n",
       " 'คาร์ดดิว',\n",
       " '<pad>',\n",
       " 'ิลิโนฮูไมต์ต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'ชคลล',\n",
       " 'แบ็ก',\n",
       " 'บอก',\n",
       " 'บัมป์',\n",
       " 'บาร์สไซต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'บบ็ก์',\n",
       " 'ก',\n",
       " 'บัมป์',\n",
       " 'บบดไตต์',\n",
       " 'ชชอิร์',\n",
       " 'ชชต',\n",
       " 'ชชง',\n",
       " 'ชัร์',\n",
       " 'ชช็กกลิสต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'าชริตต',\n",
       " 'ชิค์',\n",
       " 'ชุนกี',\n",
       " 'ชชอร์รี',\n",
       " 'ชชลล์',\n",
       " 'ชชอร์รี',\n",
       " 'ฉิมแพนซ์',\n",
       " 'ชิค',\n",
       " 'ชิน์',\n",
       " 'ชชร์ก',\n",
       " 'โคร์ตนโอ',\n",
       " 'ชชล',\n",
       " 'ีิปป',\n",
       " 'ฌัฟฟ์',\n",
       " 'ชาริตี',\n",
       " 'จชอร์',\n",
       " 'โฮว์',\n",
       " 'ตซ',\n",
       " 'ชชนต์',\n",
       " 'ชิพมูนก์',\n",
       " 'คชรอไไตต์',\n",
       " 'ชชอิส',\n",
       " 'ชชต',\n",
       " 'ชันก์',\n",
       " 'ชชป',\n",
       " 'าชร์',\n",
       " 'ูัตโดวน์',\n",
       " 'าคอร์ไลต์',\n",
       " 'ชิลี',\n",
       " 'ชชส',\n",
       " 'ุัปปอร์ต์์์์์์์์์์',\n",
       " 'โซลาริส์',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " 'ซซิมปซอไนต์ต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'ซัปพิริน',\n",
       " 'ซซซ',\n",
       " '<pad>',\n",
       " 'ซิน์',\n",
       " '<pad>',\n",
       " 'ซิง',\n",
       " 'ซซน',\n",
       " 'ซู',\n",
       " '<pad>',\n",
       " 'ซาอสซูไรต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'ซี',\n",
       " 'ซานบอร์ไนต์',\n",
       " 'ซู',\n",
       " 'นซูตตต์',\n",
       " 'าซลไลต์',\n",
       " 'ัปู',\n",
       " 'ิิตริน',\n",
       " 'ซินฮาไลต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'ะค',\n",
       " 'ซิตคอม',\n",
       " 'ิิตราต',\n",
       " 'ซิลลิมาไนต์ต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'ริ',\n",
       " 'ริ',\n",
       " 'ซซปิโอไลต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต',\n",
       " 'ซซ',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " 'ซิง',\n",
       " 'ซิลิกา',\n",
       " 'ูัรร์',\n",
       " 'อินนามอน์',\n",
       " 'ซิลไไไตต์ต์ต์ต์',\n",
       " 'คครามิก์',\n",
       " '<pad>',\n",
       " 'ตทโกไรต์ต์ต์ต์ต์ต์ต์',\n",
       " 'ซามาร์สไซต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต',\n",
       " 'ซาร์ด',\n",
       " '<pad>',\n",
       " 'ซิป',\n",
       " 'ะิรร์',\n",
       " '<pad>',\n",
       " 'ซอนี',\n",
       " 'ิิคคดา',\n",
       " 'ซิร์คา',\n",
       " 'อาโอนอตไลต์ต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'าซก',\n",
       " 'ซซ',\n",
       " 'ซูน์',\n",
       " 'รค',\n",
       " 'ซซ',\n",
       " 'าคลิินดรไรต์ต์ต์ต์ต์ต์',\n",
       " 'ดด',\n",
       " 'ดาว์โซไนต์ต์ต์ต์ต์ต์ต์',\n",
       " 'ดรรมา',\n",
       " 'ดาราปสไไไตต์ต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'ดดชิไลต์',\n",
       " 'ดดบัต',\n",
       " 'ดดลิ',\n",
       " 'ๆีพ',\n",
       " 'ดดนาโม',\n",
       " 'ดู',\n",
       " 'ดานบูไรต์ต์ต์ต์ต์ต์ต์',\n",
       " 'ดดดดี',\n",
       " 'ดร็อป์',\n",
       " 'ดดน',\n",
       " 'ดดน',\n",
       " 'ดดลล์',\n",
       " 'ดูบ',\n",
       " 'ทดลิลิลายล์',\n",
       " 'ดิซาคคาร์ไรต์',\n",
       " 'ๆีพ',\n",
       " 'ดูนดาไซต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต',\n",
       " 'ดดซิกน',\n",
       " 'ตริโปลี',\n",
       " 'โทร์',\n",
       " 'ทราฟฟิก์',\n",
       " 'ทรากตออร์อร์อร์อร์อร์อร์อร์อร์อร์อร์อร์',\n",
       " 'โกลด์',\n",
       " 'ทอรไรต์',\n",
       " 'ทตโซไนต์ต์ต์ต์ต์ต์',\n",
       " '<pad>',\n",
       " 'ทท',\n",
       " 'โทนี',\n",
       " 'ตริโคลซซน์',\n",
       " '<pad>',\n",
       " 'ททร',\n",
       " '<pad>',\n",
       " 'ททช',\n",
       " '<pad>',\n",
       " 'โทอริสต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'ททนาคไซต์',\n",
       " 'ตัวโด',\n",
       " 'ทอมโซไนต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'ตริ',\n",
       " 'ทู',\n",
       " 'ททททโน',\n",
       " 'ตริป์',\n",
       " 'าทก',\n",
       " 'โทววนโฮซ',\n",
       " 'ุัรร์มูไอซ์',\n",
       " 'แตนทาไลต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'ทอฟฟฟ',\n",
       " 'ทอม',\n",
       " 'นอร์',\n",
       " 'นนทบกกก',\n",
       " 'นิคคอไลต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'นน้ากิไอต์',\n",
       " 'นนอน',\n",
       " 'นิว',\n",
       " 'นนาซา',\n",
       " 'นนตบาลล์',\n",
       " 'นนคโคไลต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'นกอากัไลต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต',\n",
       " 'นนิกกลับบ',\n",
       " 'นา',\n",
       " 'นนาซา',\n",
       " 'นาตู',\n",
       " 'นอร์ทูไพต์ต์ต์ต์ต์ต์ต์',\n",
       " 'บัลรัส',\n",
       " 'ะอลทวอไดต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'บาร์',\n",
       " 'บบโลว์',\n",
       " 'บิสกัยตต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'ุัลบอส',\n",
       " 'บิสโทร',\n",
       " 'บัง',\n",
       " 'บิดาสซล',\n",
       " 'บบร์',\n",
       " '<pad>',\n",
       " 'ุัก',\n",
       " 'บลลนด',\n",
       " 'บลูฟ์',\n",
       " 'ุัต',\n",
       " 'บอตตอม',\n",
       " 'บรรก',\n",
       " 'แบลสต์',\n",
       " 'ูบกูส',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " 'บีวาร์',\n",
       " 'บิตมาป',\n",
       " 'บอนบอน',\n",
       " 'บบก',\n",
       " 'บิ',\n",
       " 'บาร์มบี',\n",
       " 'บรูม',\n",
       " '<pad>',\n",
       " 'บบซิน์',\n",
       " 'ุอยโคตตต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'บอไนต์',\n",
       " 'โบยฟรีนด์',\n",
       " 'บรอคคอลีย',\n",
       " 'บีฟ',\n",
       " 'บาริสตา์',\n",
       " 'บัลบ',\n",
       " 'ูอว์ลิงไตต์',\n",
       " 'บบร์น',\n",
       " 'บอย',\n",
       " 'บบร์ฟ',\n",
       " 'บล็อบ',\n",
       " 'บบน์',\n",
       " 'บบ็ปติสม',\n",
       " 'บบต',\n",
       " 'บราส์',\n",
       " 'ะรร',\n",
       " 'บัร์นอต',\n",
       " 'บลูดสตอน',\n",
       " '<pad>',\n",
       " 'บิกไไตต์ต์ต์ต์ต์ต',\n",
       " '<pad>',\n",
       " 'บลลนช์',\n",
       " 'บราวน',\n",
       " 'บรี',\n",
       " 'บรอว',\n",
       " 'บบง',\n",
       " 'บบนบอ',\n",
       " 'บัร์ป',\n",
       " 'บบนดานนา',\n",
       " 'บรรกานไทน',\n",
       " 'บัสต์',\n",
       " '<pad>',\n",
       " 'บลูนต์',\n",
       " '<pad>',\n",
       " 'บบนนอก์',\n",
       " 'บัล',\n",
       " 'บรูม',\n",
       " 'บอล์',\n",
       " 'บิล',\n",
       " 'บบซิลลัส์',\n",
       " 'บรรอด',\n",
       " 'บบ็กโดร็อป์',\n",
       " 'แบลสต์',\n",
       " 'ุัลดด',\n",
       " 'บิโปลาร์ร์์ร์์ร์์ร์์ร์',\n",
       " 'บบกอน',\n",
       " 'บบ็ปติสม',\n",
       " 'ะบดี่กอร์ด์์์์์์์์์์',\n",
       " 'บาร์โยนี',\n",
       " 'บาร์',\n",
       " 'บบดมินตอน',\n",
       " 'บริด',\n",
       " 'แบล็ก',\n",
       " 'บอมแบสติก์',\n",
       " 'ุัลดัป',\n",
       " 'บรู',\n",
       " 'บบลซา',\n",
       " 'บรร',\n",
       " 'บรอคคอลีย',\n",
       " 'บบซิก',\n",
       " 'ุบส',\n",
       " '<pad>',\n",
       " 'บัรสต์',\n",
       " 'บลอนด์',\n",
       " 'ับ',\n",
       " 'บัก',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " 'บอ',\n",
       " 'บัร์สาร์',\n",
       " 'บิสมูทิไนต์ต์ต์ต์',\n",
       " 'บาร์',\n",
       " 'ูัรรตต์',\n",
       " 'บรี',\n",
       " 'ุัลโด',\n",
       " 'บร็อก์',\n",
       " 'บบงก',\n",
       " 'บาลซี',\n",
       " 'บริสก',\n",
       " 'บบส์',\n",
       " 'บั',\n",
       " 'บรอน',\n",
       " 'บลู',\n",
       " 'บอร์กา',\n",
       " 'บริก',\n",
       " 'บี',\n",
       " 'ุัฟฟาลล',\n",
       " 'บัร์นอต',\n",
       " 'บอร์ไนต์',\n",
       " '<pad>',\n",
       " 'บลลน',\n",
       " 'บบลลิสติก์',\n",
       " 'บิโอดาตา',\n",
       " '<pad>',\n",
       " 'บลิป์',\n",
       " 'บบบอป',\n",
       " 'บินต์',\n",
       " '<pad>',\n",
       " 'บรี',\n",
       " 'บลูก',\n",
       " 'บาต',\n",
       " '<pad>',\n",
       " 'บิล์',\n",
       " '<pad>',\n",
       " 'บรรโคไไตต์ต์ต์ต์ต์ต์',\n",
       " 'บบนอฟฟฟ',\n",
       " 'บิร์ช',\n",
       " 'บบก',\n",
       " 'พาริฟิช ปิ',\n",
       " '<pad>',\n",
       " 'พลาส',\n",
       " 'โพรโมต',\n",
       " 'ปริ',\n",
       " 'โพร',\n",
       " 'ปาลม',\n",
       " 'โพร',\n",
       " 'พินิต',\n",
       " 'ๆิต บัล์',\n",
       " 'าาร์',\n",
       " 'ปลาดฟอร์ม',\n",
       " 'โพรโทต',\n",
       " 'ปรูน',\n",
       " 'ๆิต บัล์',\n",
       " 'โพร',\n",
       " 'แพโคโนไลต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'พพรโร',\n",
       " 'โพรโทต',\n",
       " 'ะานาซอนิก์',\n",
       " 'โพล',\n",
       " 'ปอร์ตลานไดต์ต์ต์ต์ต์ต์',\n",
       " 'ะาร์กาไซต์',\n",
       " 'โพรสไทต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต',\n",
       " 'โพซ',\n",
       " 'ปริ',\n",
       " 'พิรามิด์์์',\n",
       " 'ปลัม',\n",
       " 'แพ็กกา',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " 'แพ็กกา',\n",
       " 'ปลูต',\n",
       " 'โพร',\n",
       " '<pad>',\n",
       " 'ปลาทินัม',\n",
       " 'พลลโอแคลซ',\n",
       " 'โพรโมไทต์',\n",
       " 'ออนทิโมนี',\n",
       " 'ปพทน',\n",
       " 'ๆิต บัล์',\n",
       " 'ปิก',\n",
       " 'พิโคโน',\n",
       " 'โพลิบาไซต์ต์ต์',\n",
       " '<pad>',\n",
       " 'ปลาดฟอร์ม',\n",
       " 'ฟอนต์',\n",
       " 'ฟาสต์ฟอดดดดดดดดดดดดดด',\n",
       " 'ภาร์มา',\n",
       " 'ฟากบอก',\n",
       " '<pad>',\n",
       " 'ฟาสิโอน์',\n",
       " 'ฟอต์',\n",
       " 'ฟฟนนนช',\n",
       " 'ฟฟร์',\n",
       " 'ฟรัต คคก',\n",
       " 'พอสโอไรต์ต์ต์ต์ต์ต์',\n",
       " 'ฟลลา',\n",
       " 'ฟฟีย',\n",
       " 'ฟามิลี',\n",
       " 'ฟอร์กลิฟต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'ฟากบอก',\n",
       " 'ฟลูต',\n",
       " 'ฟรานชิซ',\n",
       " 'ฟลูออไรน',\n",
       " 'ฟรียบอร์ไกต์ต์ต์ต์ต์ต์ต',\n",
       " 'ฟิล',\n",
       " 'ฟฟร์กูโซไนต์ต์ต์ต์ต์ต์ต์',\n",
       " 'ฟรูกโทซ',\n",
       " 'พอสโพรูส์',\n",
       " 'ฟุนช์ตอน',\n",
       " 'ุอส',\n",
       " 'มาริโอ',\n",
       " 'โมลิบ',\n",
       " 'มมลิพาน',\n",
       " 'มาสก',\n",
       " 'มอร์กาไนต์',\n",
       " 'มัก',\n",
       " 'มิล',\n",
       " 'มอท',\n",
       " 'มมทิลลลโลลลล',\n",
       " '<pad>',\n",
       " 'มอลลกูล',\n",
       " 'มมซิก์',\n",
       " 'มิโครโคมปู',\n",
       " 'มาร์ก์',\n",
       " 'มอลดาไไไตต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต',\n",
       " 'มาร์',\n",
       " 'มาร์การ์ต',\n",
       " 'มมทาน',\n",
       " 'มาสก',\n",
       " 'มอซซิก',\n",
       " 'มมาย',\n",
       " 'มาลาโอน์',\n",
       " 'ุัมมี',\n",
       " 'มอนิตอร์อร์อร์อร์',\n",
       " 'มมก',\n",
       " 'มมนา',\n",
       " 'มาลโทซ',\n",
       " 'มิครอน',\n",
       " 'มมลิไลต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'มิ',\n",
       " 'มาลาชิต์',\n",
       " 'มมู',\n",
       " 'แมกโนไซต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'มิลลิไซต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'ุุฟฟินไรซิน',\n",
       " 'มิโครโอฟต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'บบสูส',\n",
       " 'ูู',\n",
       " 'ููนนียอ',\n",
       " 'บัม์',\n",
       " 'ููราโน',\n",
       " '<pad>',\n",
       " 'ิิปซี',\n",
       " 'อู',\n",
       " 'ีี',\n",
       " 'รีวินด์',\n",
       " 'รี',\n",
       " 'รีโลการ์',\n",
       " 'รูทท',\n",
       " 'รี',\n",
       " 'รีโมต',\n",
       " 'วริสต์',\n",
       " 'รรนซมมาร์',\n",
       " 'รรส',\n",
       " 'รีโม',\n",
       " 'รรินทท',\n",
       " 'รรูบี',\n",
       " 'รอบินซอน',\n",
       " 'รริน',\n",
       " 'รรบอต',\n",
       " 'รรดาร์ร์',\n",
       " 'โร',\n",
       " 'ลิปซซิน์ต์ต์ต์',\n",
       " 'ลลโนโก',\n",
       " 'ลิ',\n",
       " 'ลอกโดวน์',\n",
       " 'ลู',\n",
       " 'ลลตียน',\n",
       " 'ลิโอ',\n",
       " 'ลลโอ',\n",
       " 'ลล',\n",
       " 'โลอการิทม',\n",
       " 'ลลตต์',\n",
       " 'ลิป บาล์ม',\n",
       " 'ลล็ปตอป',\n",
       " 'ลลอไอต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'ลลนดมาร์ก์์',\n",
       " 'ลลอน',\n",
       " 'ลาบรา',\n",
       " 'ลลิก',\n",
       " 'ลลดลาไมต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'ลิทิโอไพไลต์ต์ต์ต์ต์ต์ต์ต์ต',\n",
       " 'ลิซาร์ไดต์',\n",
       " '<pad>',\n",
       " 'วอร์ม',\n",
       " 'วิน',\n",
       " '๊ิตามิน 1',\n",
       " 'ะกลูม',\n",
       " 'วีโลชิรัปตอร์อร์อร์อร์อร์อร์อร์อร์อร์อร์',\n",
       " 'ไวตาลิต',\n",
       " '4ิดีโอ ซาลล์',\n",
       " 'ะค็กตอร์อร์',\n",
       " 'วาลปูร์ไรต์ต์ต์ต์ต์ต์ต์',\n",
       " 'วินโดวส์',\n",
       " 'วานา',\n",
       " 'วา',\n",
       " 'ิิสตา',\n",
       " 'ออน์ไดย์',\n",
       " 'วาตทัปปป์์์์์์์ปป',\n",
       " 'ุิ',\n",
       " 'ูู',\n",
       " 'ววยราไไไตต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'วว็บ',\n",
       " 'ะา',\n",
       " 'วอร์คคอป',\n",
       " 'ววสตตต์ต์ต์ต์',\n",
       " '๊อล',\n",
       " 'ซแคน',\n",
       " 'ซ',\n",
       " 'าแตนด์',\n",
       " '<pad>',\n",
       " 'าสกานนา',\n",
       " 'ุทาสฟูไรต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต',\n",
       " 'าทาซี',\n",
       " 'สตทน',\n",
       " 'าแทก',\n",
       " 'ซปาม',\n",
       " 'สตรียมิง์',\n",
       " 'ซป็อตลิกต',\n",
       " 'สตราว',\n",
       " 'ซป็อต',\n",
       " 'ุทาโรไลต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'สตาฟฟฟ',\n",
       " 'ุ',\n",
       " 'ต',\n",
       " 'าซ',\n",
       " 'ซปิน-ออต',\n",
       " 'ซปิโนซาร์ส์',\n",
       " '8ทรต',\n",
       " 'ุทรน',\n",
       " 'ซซริปต์ต์',\n",
       " 'ซตาร์',\n",
       " 'ซมิท',\n",
       " 'ุต็อก์',\n",
       " 'ุปางโอไลต์ต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'ซวี',\n",
       " 'สติลิสต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'ศ',\n",
       " 'ซมาร์ต',\n",
       " 'ลลอยส',\n",
       " 'อิน',\n",
       " 'ออริด์',\n",
       " '6ิ',\n",
       " 'าอก',\n",
       " 'นรร์สินส',\n",
       " 'อะ',\n",
       " 'ัอซิส์',\n",
       " 'อาร์โมอร์',\n",
       " 'ออ',\n",
       " '6ิโพน',\n",
       " 'อี',\n",
       " 'ไอไดด์',\n",
       " 'ั๊อต',\n",
       " 'อะ',\n",
       " 'าอก',\n",
       " 'มมป',\n",
       " 'ออร์ต',\n",
       " 'ออฟ',\n",
       " 'ะอ',\n",
       " 'อา็กคอนต์',\n",
       " 'อีมมอนไซต์ต์ต์ต์ต์ต์ต์',\n",
       " 'ซ็อบบบ',\n",
       " 'ออร์กานิก์',\n",
       " 'โอไดน',\n",
       " 'ออลปิน',\n",
       " 'ออช์ซิ',\n",
       " 'อะมา',\n",
       " 'ออกไทนียมม',\n",
       " 'ะอร์ไทรต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'อิปาด',\n",
       " 'อิน',\n",
       " 'ออนยาา',\n",
       " 'อะบบียล์',\n",
       " 'อะนาลล',\n",
       " '6ิ',\n",
       " 'ไอโอโอไลต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต',\n",
       " 'ะอลิซ',\n",
       " 'ออดดิกต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'ออร์โทรมิิน์',\n",
       " 'อะ',\n",
       " '6ิ',\n",
       " 'ออดฟ',\n",
       " 'นินาร์ไรต์',\n",
       " 'อาลาแบส',\n",
       " 'อะโพพิลไลต์ต์ต์ต์ต์ต์ต์ต',\n",
       " 'ออ',\n",
       " 'ออลล์',\n",
       " 'ะาลูมิ',\n",
       " 'ออทาไไไตต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'อะนาโอนดา์ดาดาดาดาดาดาดาดา',\n",
       " 'ออตโท',\n",
       " 'ออร์',\n",
       " 'ออรา',\n",
       " 'ุุปลลดด',\n",
       " 'ะี',\n",
       " 'ิิต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต',\n",
       " 'อะโกชาโด',\n",
       " 'อี',\n",
       " 'อะมาลัม์',\n",
       " 'ะอไดตอร์อร์',\n",
       " 'อะโมไอลิลลิน์ล์',\n",
       " 'อะนาลไซม์',\n",
       " 'อะ',\n",
       " 'ออฟฟิ',\n",
       " 'ออลมานดิน',\n",
       " 'ะอริโอไนต์ต์ต์ต์ต์ต์',\n",
       " 'อะซอน',\n",
       " 'อะแปช',\n",
       " 'ะอโต',\n",
       " 'ออปาล',\n",
       " 'อะดร์นาลล์',\n",
       " 'อาลลอย',\n",
       " 'มมก',\n",
       " 'ออนทิโมนี',\n",
       " 'ะอ',\n",
       " 'ออม',\n",
       " 'ุัลตราไวด์',\n",
       " 'แอกิไรต์',\n",
       " 'ออปปลล',\n",
       " 'อิป์',\n",
       " 'อาแบนไดต์ต์ต์ต์ต์ต์ต์',\n",
       " 'อาลกโนโนไม',\n",
       " '<pad>',\n",
       " 'ออมพิ',\n",
       " '5ออร์โอร์โปรไทต์',\n",
       " 'อาราย',\n",
       " 'ออ',\n",
       " 'ออชไมต์ต์ต์ต์ต์ต์',\n",
       " 'ออริซ',\n",
       " 'อาร์',\n",
       " 'อิน',\n",
       " 'ออดมิตต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'อะ',\n",
       " 'โอออส',\n",
       " 'ออน',\n",
       " 'อาร์',\n",
       " 'ออนกิโลซอรูส์',\n",
       " 'ออลมานไดต์ต์ต์ต์ต์ต์ต์',\n",
       " 'โอโอไซต์',\n",
       " 'ออนทิบอดี',\n",
       " 'อาโครไไต์ต์',\n",
       " 'ฮฮลที',\n",
       " 'ฮฮส',\n",
       " 'ฮาร์ดวาร์',\n",
       " 'ฮิดดดไนต์ต์ต',\n",
       " 'ฮฮโดรกรอส',\n",
       " 'ฮฮลท์',\n",
       " 'ฮฮร์ต',\n",
       " 'ฮฮดรา',\n",
       " 'ฮาสา',\n",
       " 'ฮอวลิต์',\n",
       " 'ฮาร์ริกาน',\n",
       " 'ฮา',\n",
       " 'ฮัรรริคาน',\n",
       " 'ฮายไนต์',\n",
       " 'ฮอ',\n",
       " 'ฮอ',\n",
       " 'ฮูแลนไดต์ต์ต์ต์',\n",
       " 'ฮานไซต์',\n",
       " 'ฮาร์รี',\n",
       " 'ฮันด์',\n",
       " 'ฮาร์ดิสโทไนต์ต์ต์ต์ต์ต์ต์ต์ต์ต์',\n",
       " 'ฮอลแลนไดต์ต์ต์ต์',\n",
       " 'ฮฮดรอ',\n",
       " 'ฮอลโลกรัม์',\n",
       " 'ฮฮโปทาลามัส์',\n",
       " 'ฮฮ',\n",
       " 'ะฮ']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('5ep-pred.txt','w',encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ground_truth.txt','w',encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(test_target_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
