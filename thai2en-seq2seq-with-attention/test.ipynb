{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 23 01:29:02 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 511.69       Driver Version: 511.69       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   65C    P8     4W /  N/A |    888MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1824    C+G                                   N/A      |\n",
      "|    0   N/A  N/A     26120    C+G   ...llMobileConnectClient.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=''\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torchvision import transforms, utils\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "SEED = 0\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = os.path.join('..','dataset','cs')\n",
    "test_filepaths = os.path.join(path_dataset,'test.tsv')\n",
    "test_df = pd.read_csv(test_filepaths,sep=\"\\t\")\n",
    "train_filepaths = os.path.join(path_dataset,'train.tsv')\n",
    "train_df = pd.read_csv(train_filepaths,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    input_texts = [str(i) for i in list(data_path['word'])]\n",
    "    target_texts = [str(i) for i in list(data_path['roman'])]\n",
    "    return input_texts, target_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_texts, test_target_texts = load_data(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define special characters\n",
    "UNK_token = '<UNK>'\n",
    "PAD_token = '<PAD>'\n",
    "START_token = '<start>'\n",
    "END_token = '<end>'\n",
    "MAX_LENGTH = 60\n",
    "\n",
    "class Language:\n",
    "    def __init__(self, name,char2index={},index2char={}, is_input=False):\n",
    "        self.name = name\n",
    "        self.characters = set()\n",
    "        self.n_chars = 0\n",
    "        self.char2index = {}\n",
    "        self.index2char = {}\n",
    "\n",
    "        if is_input == True:\n",
    "            self.index2char = { 0: PAD_token, 1: UNK_token, 2: START_token, 3: END_token }\n",
    "            self.char2index = { ch:i for i, ch in self.index2char.items() } #reverse dictionary\n",
    "            self.n_chars = 4\n",
    "        else:\n",
    "            self.index2char = { 0: PAD_token, 1: START_token, 2: END_token }\n",
    "            self.char2index = { ch:i for i, ch in self.index2char.items() } #reverse dictionary\n",
    "            self.n_chars = 3\n",
    "        if char2index != {} and index2char != {}:\n",
    "            print(\"cat!!!\")\n",
    "            self.char2index = char2index\n",
    "            self.index2char = index2char\n",
    "            self.characters = set(list(self.char2index.keys()))\n",
    "\n",
    "    def addText(self, text):\n",
    "        for character in text:\n",
    "            self.addCharacter(character)\n",
    "    \n",
    "    def addCharacter(self, character):\n",
    "        if character not in self.char2index.keys():\n",
    "            self.char2index[character] = self.n_chars\n",
    "            self.index2char[self.n_chars] = character\n",
    "            self.n_chars += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromText(lang, text):\n",
    "    \"\"\"returns indexes for all character given the text in the specified language\"\"\"\n",
    "    return [lang.char2index[char] for char in text]\n",
    "\n",
    "def tensorFromText(lang, text):\n",
    "    \"\"\"construct a tensor given the text in the specified language\"\"\"\n",
    "    indexes = indexesFromText(lang, text)\n",
    "    indexes.append(lang.char2index[END_token])\n",
    "    \n",
    "    no_padded_seq_length = len(indexes) # Number of characters in the text (including <END> token)\n",
    "    # Add padding token to make all tensors in the same length\n",
    "    for i in range(len(indexes), MAX_LENGTH): # padding\n",
    "        indexes.append(lang.char2index[PAD_token])\n",
    "        \n",
    "    return torch.tensor(indexes, dtype=torch.long), no_padded_seq_length\n",
    "\n",
    "def filterPair(p1, p2):\n",
    "    \"\"\"filter for the pair the both texts has length less than `MAX_LENGTH`\"\"\"\n",
    "    return len(p1) < MAX_LENGTH and len(p2) < MAX_LENGTH\n",
    "\n",
    "def tensorsFromPair(pair, lang1, lang2):\n",
    "    \"\"\"construct two tensors from a pair of source and target text specified by source and target language\"\"\"\n",
    "    input_tensor, input_length = tensorFromText(lang1, pair[0])\n",
    "    target_tensor, target_length = tensorFromText(lang2, pair[1])\n",
    "    return input_tensor, target_tensor, input_length, target_length\n",
    "\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        input_text, target_text, lang_th, lang_th_romanized = sample['input_text'], sample['target_text'],                                                               sample['lang_th'], sample['lang_th_romanized']\n",
    "\n",
    "        input_tensor, target_tensor, input_length, target_length = tensorsFromPair([input_text, target_text], \n",
    "                                                                                   lang_th, \n",
    "                                                                                   lang_th_romanized)\n",
    "        \n",
    "        return {\n",
    "                'input_text': input_text,\n",
    "                'target_text': target_text,\n",
    "                'input_length': input_length,\n",
    "                'target_length': target_length,\n",
    "                'input_tensor': input_tensor,\n",
    "                'target_tensor': target_tensor\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThaiRomanizationDataset(Dataset):\n",
    "    \"\"\"Thai Romanization Dataset class\"\"\"\n",
    "    def __init__(self, \n",
    "                 data_path,\n",
    "                 config = {},\n",
    "                 transform=transforms.Compose([ ToTensor() ])):\n",
    "\n",
    "        input_texts, target_texts = load_data(data_path)\n",
    "        \n",
    "        self.input_texts = input_texts\n",
    "        self.target_texts = target_texts\n",
    "        self.transform = transform\n",
    "        self.lang_th = None\n",
    "        self.config=config\n",
    "        self.lang_th_romanized = None\n",
    "        self.counter = Counter()\n",
    "        self.pairs = []\n",
    "        self.prepareData()\n",
    "\n",
    "    def prepareData(self):\n",
    "        self.lang_th = Language('th', self.config['char_to_ix'],self.config['ix_to_char'],is_input=True)\n",
    "        self.lang_th_romanized = Language('th_romanized', self.config['target_char_to_ix'],self.config['ix_to_target_char'], is_input=False)\n",
    "        for i in range(len(self.input_texts)):\n",
    "            \n",
    "            input_text = str(self.input_texts[i])\n",
    "            target_text = str(self.target_texts[i])\n",
    "            \n",
    "            # Count the number of input and target sequences with length `x`\n",
    "            self.counter.update({ \n",
    "                                  'len_input_{}'.format(len(input_text)): 1, \n",
    "                                  'len_target_{}'.format(len(target_text)): 1 \n",
    "                                })\n",
    "            \n",
    "            if filterPair(input_text, target_text):\n",
    "                self.pairs.append((input_text, target_text))\n",
    "                self.lang_th.addText(input_text)\n",
    "                self.lang_th_romanized.addText(target_text)    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        sample = dict()\n",
    "        sample['input_text'] = self.pairs[idx][0]\n",
    "        sample['target_text'] = self.pairs[idx][1]\n",
    "        \n",
    "        sample['lang_th'] = self.lang_th\n",
    "        sample['lang_th_romanized'] = self.lang_th_romanized\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    return torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=load_model(\"new_model/thai2rom-pytorch-10.attn.v6.best_epoch-10.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat!!!\n",
      "cat!!!\n"
     ]
    }
   ],
   "source": [
    "thai_romanization_dataset = ThaiRomanizationDataset(train_df,config=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_2_ix, ix_2_char, target_char_to_ix, ix_to_target_char = thai_romanization_dataset.lang_th.char2index ,thai_romanization_dataset.lang_th.index2char , thai_romanization_dataset.lang_th_romanized.char2index ,  thai_romanization_dataset.lang_th_romanized.index2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocabulary_size, embedding_size, hidden_size, dropout=0.5):\n",
    "        \"\"\"Constructor\"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.character_embedding = nn.Embedding(vocabulary_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_size, \n",
    "                            hidden_size=hidden_size // 2, \n",
    "                            bidirectional=True,\n",
    "                            batch_first=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def forward(self, sequences, sequences_lengths):\n",
    "        batch_size = sequences.size(0)\n",
    "        self.hidden = self.init_hidden(batch_size) # batch_size\n",
    "\n",
    "        # sequences :(batch_size, sequence_length=MAX_LENGTH)\n",
    "        # sequences_lengths: (batch_size)  # an 1-D indicating length of each sequence (excluded <PAD> token) in `seq`\n",
    "        \n",
    "        # 1. Firstly we sort `sequences_lengths` according to theirs values and keep list of indexes to perform sorting\n",
    "        sequences_lengths = np.sort(sequences_lengths)[::-1] # sort in ascending order and reverse it\n",
    "        index_sorted = np.argsort(-sequences_lengths) # use negation in sort in descending order\n",
    "        index_unsort = np.argsort(index_sorted) # to unsorted sequence\n",
    "        \n",
    "        \n",
    "        # 2. Then, we change position of sequence in `sequences` according to `index_sorted`\n",
    "        index_sorted = torch.from_numpy(index_sorted)\n",
    "        sequences = sequences.index_select(0, index_sorted)\n",
    "        \n",
    "        # 3. Feed to Embedding Layer\n",
    "        \n",
    "        sequences = self.character_embedding(sequences)\n",
    "        sequences = self.dropout(sequences)\n",
    "        \n",
    "#         print('sequences',sequences.size(), sequences)\n",
    "            \n",
    "        # 3. Use function: pack_padded_sequence to let LSTM packed input with same length at time step T together\n",
    "        \n",
    "        # Quick fix: Use seq_len.copy(), instead of seq_len to fix `Torch.from_numpy not support negative strides`\n",
    "        # ndarray.copy() will alocate new memory for numpy array which make it normal, I mean the stride is not negative any more.\n",
    "\n",
    "        sequences_packed = nn.utils.rnn.pack_padded_sequence(sequences,\n",
    "                                                             sequences_lengths.copy(),\n",
    "                                                             batch_first=True)\n",
    "#         print('sequences_packed', sequences_packed)\n",
    "\n",
    "        # 4. Feed to LSTM\n",
    "        sequences_output, self.hidden = self.lstm(sequences_packed, self.hidden)\n",
    "        \n",
    "        # 5. Unpack\n",
    "        sequences_output, _ = nn.utils.rnn.pad_packed_sequence(sequences_output, batch_first=True)\n",
    "\n",
    "        # 6. Un-sort by length\n",
    "        index_unsort = torch.from_numpy(index_unsort)\n",
    "        sequences_output = sequences_output.index_select(0, Variable(index_unsort))\n",
    "\n",
    "#         print('hidden shape', self.hidden[0].shape, self.hidden[0], self.hidden[1].shape, self.hidden[1])\n",
    "        return sequences_output, self.hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        h_0 = torch.zeros([2, batch_size, self.hidden_size // 2], requires_grad=True)\n",
    "        c_0 = torch.zeros([2, batch_size, self.hidden_size // 2], requires_grad=True)\n",
    "        \n",
    "        return (h_0, c_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "\n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.other = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs, mask):\n",
    "        # hidden: B x 1 x h ; \n",
    "        # encoder_outputs: B x S x h\n",
    "\n",
    "        # Calculate energies for each encoder output\n",
    "        if self.method == 'dot':\n",
    "            attn_energies = torch.bmm(encoder_outputs, hidden.transpose(1, 2)).squeeze(2)  # B x S\n",
    "        elif self.method == 'general':\n",
    "            attn_energies = self.attn(encoder_outputs.view(-1, encoder_outputs.size(-1)))  # (B * S) x h\n",
    "            attn_energies = torch.bmm(attn_energies.view(*encoder_outputs.size()),\n",
    "                                      hidden.transpose(1, 2)).squeeze(2)  # B x S\n",
    "        elif self.method == 'concat':\n",
    "            attn_energies = self.attn(\n",
    "                torch.cat((hidden.expand(*encoder_outputs.size()), encoder_outputs), 2))  # B x S x h\n",
    "            attn_energies = torch.bmm(attn_energies,\n",
    "                                      self.other.unsqueeze(0).expand(*hidden.size()).transpose(1, 2)).squeeze(2)\n",
    "\n",
    "        attn_energies = attn_energies.masked_fill(mask == 0, -1e10)\n",
    "\n",
    "        # Normalize energies to weights in range 0 to 1\n",
    "        return F.softmax(attn_energies, 1)\n",
    "\n",
    "class AttentionDecoder(nn.Module): \n",
    "    \n",
    "    def __init__(self, vocabulary_size, embedding_size, hidden_size, dropout=0.5):\n",
    "        \"\"\"Constructor\"\"\"\n",
    "        super(AttentionDecoder, self).__init__()\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.character_embedding = nn.Embedding(vocabulary_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_size + self.hidden_size,\n",
    "                            hidden_size=hidden_size,\n",
    "                            bidirectional=False,\n",
    "                            batch_first=True)\n",
    "        \n",
    "        self.attn = Attn(method=\"general\", hidden_size=self.hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size * 2, vocabulary_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        \n",
    "    def forward(self, input, last_hidden, last_context, encoder_outputs, mask):\n",
    "        \"\"\"\"Defines the forward computation of the decoder\"\"\"\n",
    "        # input: (B, 1) ,\n",
    "        # last_hidden: (num_layers * num_directions, B, hidden_dim)\n",
    "        # last_context: (B, 1, hidden_dim)\n",
    "        # encoder_outputs: (B, S, hidden_dim)\n",
    "        \n",
    "        embedded = self.character_embedding(input)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        # embedded: (batch_size, emb_dim)\n",
    "        rnn_input = torch.cat((embedded, last_context), 2)\n",
    "\n",
    "        output, hidden = self.lstm(rnn_input, last_hidden)        \n",
    "        attn_weights = self.attn(output, encoder_outputs, mask)  # B x S\n",
    "    \n",
    "        #  context = (B, 1, S) x (B, S, hidden_dim)\n",
    "        #  context = (B, 1, hidden_dim)\n",
    "        context = attn_weights.unsqueeze(1).bmm(encoder_outputs)  \n",
    "        \n",
    "        output = torch.cat((context.squeeze(1), output.squeeze(1)), 1)\n",
    "        output = self.linear(output)\n",
    "        \n",
    "        return output, hidden, context, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module): \n",
    "\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.pad_idx = 0\n",
    "\n",
    "        assert encoder.hidden_size == decoder.hidden_size\n",
    "    \n",
    "    def create_mask(self, source_seq):\n",
    "        mask = (source_seq != self.pad_idx)\n",
    "        return mask\n",
    "        \n",
    "  \n",
    "    def forward(self, source_seq, source_seq_len, target_seq, teacher_forcing_ratio = 0.5):\n",
    "        \"\"\"\n",
    "            Parameters:\n",
    "                - source_seq: (batch_size x MAX_LENGTH) \n",
    "                - source_seq_len: (batch_size x 1)\n",
    "                - target_seq: (batch_size x MAX_LENGTH)\n",
    "\n",
    "            Returns\n",
    "        \"\"\"\n",
    "        batch_size = source_seq.size(0)\n",
    "        start_token = char_to_ix[\"<start>\"]\n",
    "        end_token = char_to_ix[\"<end>\"]\n",
    "        max_len = MAX_LENGTH\n",
    "        target_vocab_size = self.decoder.vocabulary_size\n",
    "\n",
    "        # init a tensor to store decoder outputs\n",
    "        outputs = torch.zeros(max_len, batch_size, target_vocab_size)\n",
    "        \n",
    "        if target_seq is None:\n",
    "            assert teacher_forcing_ratio == 0, \"Must be zero during inference\"\n",
    "            inference = True\n",
    "        else:\n",
    "            inference = False\n",
    "\n",
    "    \n",
    "        # feed mini-batch source sequences into the `Encoder`\n",
    "        encoder_outputs, encoder_hidden = self.encoder(source_seq, source_seq_len)\n",
    "\n",
    "        # create a Tensor of first input for the decoder\n",
    "        decoder_input = torch.tensor([[start_token] * batch_size]).view(batch_size, 1)\n",
    "        \n",
    "        # Initiate decoder output as the last state encoder's hidden state\n",
    "        decoder_hidden_0 = torch.cat([encoder_hidden[0][0], encoder_hidden[0][1]], dim=1).unsqueeze(dim=0)\n",
    "        decoder_hidden_1 = torch.cat([encoder_hidden[1][0], encoder_hidden[1][1]], dim=1).unsqueeze(dim=0)\n",
    "        decoder_hidden = (decoder_hidden_0, decoder_hidden_1) # (hidden state, cell state)\n",
    "\n",
    "        # define a context vector\n",
    "        decoder_context = Variable(torch.zeros(encoder_outputs.size(0), encoder_outputs.size(2))).unsqueeze(1)\n",
    "        \n",
    "        max_source_len = encoder_outputs.size(1)\n",
    "        mask = self.create_mask(source_seq[:, 0:max_source_len])\n",
    "            \n",
    "       \n",
    "        for di in range(max_len):\n",
    "            decoder_output, decoder_hidden, decoder_context, attn_weights = self.decoder(decoder_input,\n",
    "                                                                                    decoder_hidden,\n",
    "                                                                                    decoder_context,\n",
    "                                                                                    encoder_outputs,\n",
    "                                                                                    mask)\n",
    "            # decoder_output: (batch_size, target_vocab_size)\n",
    "\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            outputs[di] = decoder_output\n",
    "    \n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "\n",
    "\n",
    "            decoder_input = target_seq[:, di].reshape(batch_size, 1) if teacher_force else topi.detach() \n",
    "\n",
    "            if inference and decoder_input == end_token:\n",
    "                return outputs[:di]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, text, char_2_ix, ix_2_char, target_char_to_ix, ix_to_target_char):\n",
    "    input_seq =  [ch for ch in text] +  ['<end>']\n",
    "    numericalized = [char_2_ix[ch] for ch in input_seq] \n",
    "    \n",
    "#     print('input ',numericalized)\n",
    "    sentence_length = [len(numericalized)]\n",
    "\n",
    "    tensor = torch.LongTensor(numericalized).view(1, -1) \n",
    "    \n",
    "#     print(tensor)\n",
    "    translation_tensor_logits = model(tensor, sentence_length, None, 0) \n",
    "#     print(translation_tensor_logits)\n",
    "    if translation_tensor_logits.size(0) == 0:\n",
    "        translation_indices = [0]\n",
    "        translation = ['<pad>']\n",
    "    else:\n",
    "        translation_tensor = torch.argmax(translation_tensor_logits.squeeze(1), 1).cpu().numpy()\n",
    "        translation_indices = [t for t in translation_tensor]\n",
    "        translation = [ix_to_target_char[t] for t in translation_tensor]\n",
    "    return ''.join(translation), translation_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, ENC_DROPOUT = data['encoder_params']\n",
    "OUTPUT_DIM, DEC_EMB_DIM, DEC_HID_DIM, DEC_DROPOUT = data['decoder_params']\n",
    "\n",
    "_encoder = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM)\n",
    "_decoder = AttentionDecoder(OUTPUT_DIM, DEC_EMB_DIM, DEC_HID_DIM)\n",
    "\n",
    "#model = Seq2Seq(_encoder, _decoder)\n",
    "model = Seq2Seq(_encoder, _decoder)\n",
    "model.load_state_dict(data['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_ix = data['char_to_ix']\n",
    "ix_to_char =  data['ix_to_char']\n",
    "target_char_to_ix = data['target_char_to_ix']\n",
    "ix_to_target_char = data['ix_to_target_char']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_2_ix=char_to_ix\n",
    "ix_2_char=ix_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (character_embedding): Embedding(94, 128)\n",
       "    (lstm): LSTM(128, 128, batch_first=True, bidirectional=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): AttentionDecoder(\n",
       "    (character_embedding): Embedding(39, 128)\n",
       "    (lstm): LSTM(384, 256, batch_first=True)\n",
       "    (attn): Attn(\n",
       "      (attn): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (linear): Linear(in_features=512, out_features=39, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text=\"แมว\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, indices = inference(model, input_text, char_2_ix, ix_2_char, target_char_to_ix, ix_to_target_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'qxw'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.replace('<end>','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference2(model, text, char_2_ix, ix_2_char, target_char_to_ix, ix_to_target_char):\n",
    "    input_seq =  [ch for ch in text] +  ['<end>']\n",
    "    numericalized = [char_2_ix[ch] for ch in input_seq] \n",
    "    \n",
    "#     print('input ',numericalized)\n",
    "    sentence_length = [len(numericalized)]\n",
    "\n",
    "    tensor = torch.LongTensor(numericalized).view(1, -1) \n",
    "    return tensor, sentence_length, None, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run2(word):\n",
    "    return inference2(model, word, char_2_ix, ix_2_char, target_char_to_ix, ix_to_target_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(word):\n",
    "    prediction, indices = inference(model, word, char_2_ix, ix_2_char, target_char_to_ix, ix_to_target_char)\n",
    "    return prediction.replace('<end>','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[15, 29, 15,  3]]), [4], None, 0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run2(\"นอน\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'è雄èè'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\"นอน\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_input_texts, test_target_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=[]\n",
    "model.eval()\n",
    "for i in tqdm(test_input_texts):\n",
    "    pred.append(run(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jiwer import cer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('10ep-pred.txt','r',encoding='utf-8-sig') as f:\n",
    "#     test_target_texts=[i.strip() for i in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('ground_truth.txt','r',encoding='utf-8-sig') as f:\n",
    "#     pred=[i.strip() for i in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9462802289089902"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cer(test_target_texts,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('10ep-pred.txt','w',encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ground_truth.txt','w',encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(test_target_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
